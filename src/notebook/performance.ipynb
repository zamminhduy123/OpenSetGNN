{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d403db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('/home/ntmduy/GraphAE/src/model')))\n",
    "sys.path.append(os.path.join(os.path.dirname('/home/ntmduy/GraphAE/src/utils')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "016f6f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.GAE_Projection_Att import GAE_CLS_Link_NODE_Cosine_SupCon_2\n",
    "from model.resnet_big import SupCEResNet, SupConResNet, LinearClassifier, SupIncepResnet\n",
    "import torch\n",
    "from torch_geometric.nn import summary\n",
    "from thop import profile\n",
    "import numpy as np\n",
    "import time\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils.data import load_and_split_graphs\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519af486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03a2b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_gpu(dummy_input, model, device, rep, none_gnn=False):\n",
    "    model = model.to(device=device)\n",
    "    # dummy_input = torch.randn(1, 1, 29, 29, dtype=torch.float).to(device)\n",
    "    # INIT LOGGERS\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = rep\n",
    "    timings=np.zeros((repetitions,1))\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(100):\n",
    "        if (none_gnn):\n",
    "            _ = model(dummy_input)\n",
    "        else:\n",
    "            _ = model(dummy_input, device, acummulate = True, remove_random=True)\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            starter.record()\n",
    "            if (none_gnn):\n",
    "                _ = model(dummy_input)\n",
    "            else:\n",
    "                _ = model(dummy_input, device, acummulate = True, remove_random=True)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0966f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_cpu(model, device, rep = 10):\n",
    "    model = model.to(device=device)\n",
    "    x = torch.rand((1, 1, 29, 29), device=device)\n",
    "    timings=np.zeros((rep,1))\n",
    "    for i in range(rep):    \n",
    "        start_time = time.time()\n",
    "        out = model(x)\n",
    "        timings[i] = time.time() - start_time\n",
    "    mean_syn = np.sum(timings) / rep\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "854217cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(model, test_loader, device='cuda', num_warmup=10, num_repeats=100):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        print(f\"Warming up for {num_warmup} iterations...\")\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            _ = model(batch, device, acummulate = True, remove_random=True)\n",
    "            if i >= num_warmup - 1:\n",
    "                break\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Starting timed inference over {num_repeats} iterations...\")\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= num_repeats:\n",
    "                break\n",
    "            batch = batch.to(device)\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.perf_counter()\n",
    "            _ = model(batch, device, acummulate = True, remove_random=True)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.perf_counter()\n",
    "            times.append(end_time - start_time)\n",
    "\n",
    "        times = np.array(times)\n",
    "        print(f\"Tested {len(times)} samples.\")\n",
    "        print(f\"Mean Latency: {np.mean(times)*1000:.2f} ms\")\n",
    "        print(f\"Median Latency: {np.median(times)*1000:.2f} ms\")\n",
    "        print(f\"Throughput: {1/np.mean(times):.2f} samples/sec\")\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "            print(f\"Max GPU memory used: {mem:.2f} MB\")\n",
    "            torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215aaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'/home/ntmduy/GraphAE/data/mas/WS_300/step_300/9/edge_features_3/normalized_except_id/raw/sort_seperated'\n",
    "\n",
    "train_graphs, test_graphs, graphs_names = load_and_split_graphs(path, exclude=[], train_ratio=0.8, seed=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1314d766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1943430/3614810919.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  graph.edge_attr = torch.tensor(graph.edge_attr[:, 0].reshape(-1, 1), dtype=torch.float32)\n",
      "/tmp/ipykernel_1943430/3614810919.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input.edge_attr = torch.tensor(dummy_input.edge_attr[:, 0].reshape(-1, 1), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "warmup_loader = DataLoader([train_graphs[0]], batch_size=1, shuffle=False)\n",
    "\n",
    "for graph in test_graphs:\n",
    "    graph.edge_attr = torch.tensor(graph.edge_attr[:, 0].reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "test_loader = DataLoader(test_graphs, batch_size=64, shuffle=False)\n",
    "\n",
    "dummy_input = next(iter(warmup_loader)).to('cuda')\n",
    "dummy_input.edge_attr = torch.tensor(dummy_input.edge_attr[:, 0].reshape(-1, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a467ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.7600102066993712, 0.20232976952404977)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAE_CLS_Link_NODE_Cosine_SupCon_2(num_features=9, embedding_size=32, projection_emb=128, activate='gelu', layer_type='gatv2', num_layers=2, directed=False, id_dim=1, num_classes = 5, linear_node=True, num_id_embeddings=2048, attn_head=1)\n",
    "measure_time_gpu(dummy_input, model, 'cuda', rep=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98e4d174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.999163134098053, 0.23098467288391075)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incep = SupIncepResnet(num_classes=5)\n",
    "measure_time_gpu(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(), incep, 'cuda', rep=1000, none_gnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9698673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up for 10 iterations...\n",
      "Starting timed inference over 100 iterations...\n",
      "Tested 19 samples.\n",
      "Mean Latency: 3.83 ms\n",
      "Median Latency: 3.82 ms\n",
      "Throughput: 261.19 samples/sec\n",
      "Max GPU memory used: 17.34 MB\n"
     ]
    }
   ],
   "source": [
    "analyze_performance(model, test_loader, device='cuda', num_warmup=10, num_repeats=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30a05d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gnn_model(model, example_data, device=None, repeat=10):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device).eval()\n",
    "    example_data = example_data.to(device)\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                 record_shapes=True,\n",
    "                 profile_memory=True,\n",
    "                 with_flops=True) as prof:\n",
    "        with torch.no_grad():\n",
    "            for _ in range(repeat):\n",
    "                with record_function(\"model_inference\"):\n",
    "                    model(example_data)\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=15))\n",
    "    print(prof.key_averages().table(sort_by=\"flops\", row_limit=15))\n",
    "    # For total FLOPs (note: double to get MACs for real-valued ops)\n",
    "    total_flops = sum([item.flops for item in prof.key_averages() if hasattr(item, 'flops')])\n",
    "    print(f\"Estimated total FLOPs: {total_flops}\")\n",
    "    print(f\"Estimated total MACs: {total_flops/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fba16d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-06-04 11:58:42 1943430:1943430 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-06-04 11:58:42 1943430:1943430 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-06-04 11:58:42 1943430:1943430 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     aten::scatter_add_         2.10%       2.485ms         2.96%       3.495ms      29.125us     180.000us        16.59%     180.000us       1.500us           0 b           0 b           0 b           0 b           120            --  \n",
      "void at::native::_scatter_gather_elementwise_kernel<...         0.00%       0.000us         0.00%       0.000us       0.000us     180.000us        16.59%     180.000us       1.500us           0 b           0 b           0 b           0 b           120            --  \n",
      "                                            aten::addmm         1.37%       1.617ms         1.96%       2.318ms      57.950us     142.000us        13.09%     142.000us       3.550us           0 b           0 b     360.00 Kb     360.00 Kb            40      3778.560  \n",
      "                                     aten::index_select         2.62%       3.100ms         5.49%       6.491ms      46.364us     140.000us        12.90%     140.000us       1.000us           0 b           0 b       1.39 Mb           0 b           140            --  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     100.000us         9.22%     100.000us       1.000us           0 b           0 b           0 b           0 b           100            --  \n",
      "                                              aten::add         1.90%       2.245ms         2.68%       3.164ms      26.367us     100.000us         9.22%     100.000us       0.833us           0 b           0 b       1.04 Mb       1.04 Mb           120       268.320  \n",
      "                                              aten::mul         1.64%       1.935ms         2.33%       2.755ms      27.550us     100.000us         9.22%     100.000us       1.000us           0 b           0 b       1.19 Mb       1.19 Mb           100       266.880  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      84.000us         7.74%      84.000us       0.933us           0 b           0 b           0 b           0 b            90            --  \n",
      "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      82.000us         7.56%      82.000us       2.050us           0 b           0 b           0 b           0 b            40            --  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      80.000us         7.37%      80.000us       1.000us           0 b           0 b           0 b           0 b            80            --  \n",
      "                                              aten::div         1.17%       1.379ms         1.67%       1.973ms      24.663us      80.000us         7.37%      80.000us       1.000us           0 b           0 b     220.00 Kb     220.00 Kb            80            --  \n",
      "void splitKreduce_kernel<32, 16, int, float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      60.000us         5.53%      60.000us       1.500us           0 b           0 b           0 b           0 b            40            --  \n",
      "                                  aten::scatter_reduce_         0.50%     593.000us         1.06%       1.256ms      62.800us      42.000us         3.87%      62.000us       3.100us           0 b           0 b           0 b           0 b            20            --  \n",
      "void at::native::_scatter_gather_elementwise_kernel<...         0.00%       0.000us         0.00%       0.000us       0.000us      42.000us         3.87%      42.000us       2.100us           0 b           0 b           0 b           0 b            20            --  \n",
      "                                              aten::sum         0.50%     590.000us         0.67%     790.000us      39.500us      40.000us         3.69%      40.000us       2.000us           0 b           0 b      20.00 Kb      20.00 Kb            20            --  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 118.213ms\n",
      "Self CUDA time total: 1.085ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm         1.37%       1.617ms         1.96%       2.318ms      57.950us     142.000us        13.09%     142.000us       3.550us           0 b           0 b     360.00 Kb     360.00 Kb            40      3778.560  \n",
      "                                              aten::add         1.90%       2.245ms         2.68%       3.164ms      26.367us     100.000us         9.22%     100.000us       0.833us           0 b           0 b       1.04 Mb       1.04 Mb           120       268.320  \n",
      "                                              aten::mul         1.64%       1.935ms         2.33%       2.755ms      27.550us     100.000us         9.22%     100.000us       1.000us           0 b           0 b       1.19 Mb       1.19 Mb           100       266.880  \n",
      "                                               aten::mm         0.50%     587.000us         0.65%     764.000us      38.200us      20.000us         1.84%      20.000us       1.000us           0 b           0 b     340.00 Kb     340.00 Kb            20       174.080  \n",
      "                                        model_inference        33.65%      39.782ms        99.97%     118.178ms      11.818ms       0.000us         0.00%       1.085ms     108.500us     271.26 Kb    -124.87 Kb    -279.00 Kb      -6.60 Mb            10            --  \n",
      "                                               aten::to         2.16%       2.553ms        30.60%      36.174ms      26.213us       0.000us         0.00%      27.000us       0.020us     396.11 Kb          24 b     340.00 Kb         512 b          1380            --  \n",
      "                                         aten::_to_copy         6.54%       7.727ms        28.42%      33.599ms      32.557us       0.000us         0.00%      27.000us       0.026us     396.11 Kb       1.83 Kb     340.00 Kb           0 b          1032            --  \n",
      "                                    aten::empty_strided         4.64%       5.480ms         4.64%       5.480ms       5.259us       0.000us         0.00%       0.000us       0.000us     394.28 Kb     394.28 Kb     430.00 Kb     430.00 Kb          1042            --  \n",
      "                                            aten::copy_         9.00%      10.639ms        17.70%      20.926ms      20.083us      37.000us         3.41%      37.000us       0.036us           0 b           0 b           0 b           0 b          1042            --  \n",
      "                                        cudaMemcpyAsync         7.12%       8.413ms         7.12%       8.413ms       8.074us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1042            --  \n",
      "                       Memcpy DtoH (Device -> Pageable)         0.00%       0.000us         0.00%       0.000us       0.000us      27.000us         2.49%      27.000us       0.051us           0 b           0 b           0 b           0 b           532            --  \n",
      "                                  cudaStreamSynchronize         1.59%       1.874ms         1.59%       1.874ms       1.816us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1032            --  \n",
      "                aten::_has_compatible_shallow_copy_type         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1180            --  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           500            --  \n",
      "                                           aten::linear         0.43%     507.000us         3.69%       4.363ms      72.717us       0.000us         0.00%     162.000us       2.700us           0 b           0 b     700.00 Kb           0 b            60            --  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 118.213ms\n",
      "Self CUDA time total: 1.085ms\n",
      "\n",
      "Estimated total FLOPs: 4487840\n",
      "Estimated total MACs: 2243920.0\n"
     ]
    }
   ],
   "source": [
    "dummy_input = dummy_input.to(device='cpu')\n",
    "model = model.to(device='cpu')\n",
    "profile_gnn_model(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a89fc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+-----------------------------------+------------------------------+-------------------------------+----------+\\n| Layer                             | Input Shape                  | Output Shape                  | #Param   |\\n|-----------------------------------+------------------------------+-------------------------------+----------|\\n| GAE_CLS_Link_NODE_Cosine_SupCon_2 | [72, 72]                     | [72, 32]                      | 74,715   |\\n| ├─(id_embedding)Embedding         | --                           | --                            | 2,048    |\\n| ├─(encoder)Graph_Encoder_Norm     | [72, 9], [2, 136], [136, 1]  | [72, 32], [72, 32], [2304, 2] | 3,154    |\\n| │    └─(bn)BatchNorm1d            | --                           | --                            | 18       |\\n| │    └─(convs)ModuleList          | --                           | --                            | 2,944    |\\n| │    │    └─(0)GATv2Conv          | [72, 9], [2, 136], [136, 1]  | [72, 32]                      | 736      |\\n| │    │    └─(1)GATv2Conv          | [72, 32], [2, 136], [136, 1] | [72, 32]                      | 2,208    |\\n| │    └─(norms)ModuleList          | --                           | --                            | 192      |\\n| │    │    └─(0)GraphNorm          | [72, 32]                     | [72, 32]                      | 96       |\\n| │    │    └─(1)GraphNorm          | [72, 32]                     | [72, 32]                      | 96       |\\n| │    └─(activate_function)GELU    | [72, 32]                     | [72, 32]                      | --       |\\n| ├─(linear)Sequential              | --                           | --                            | 24,832   |\\n| │    └─(0)Linear                  | --                           | --                            | 8,320    |\\n| │    └─(1)GELU                    | --                           | --                            | --       |\\n| │    └─(2)Dropout                 | --                           | --                            | --       |\\n| │    └─(3)Linear                  | --                           | --                            | 16,512   |\\n| ├─(read_out)Set2Set               | --                           | --                            | 20,992   |\\n| │    └─(lstm)LSTM                 | --                           | --                            | 20,992   |\\n| ├─(decoder)MLPDecoder             | --                           | --                            | 21,513   |\\n| │    └─(mlp)Sequential            | --                           | --                            | 21,513   |\\n| │    │    └─(0)Linear             | --                           | --                            | 16,896   |\\n| │    │    └─(1)ReLU               | --                           | --                            | --       |\\n| │    │    └─(2)Linear             | --                           | --                            | 4,617    |\\n| ├─(node_out_1)Linear              | --                           | --                            | 1,056    |\\n| ├─(node_out_2)Linear              | --                           | --                            | 1,056    |\\n+-----------------------------------+------------------------------+-------------------------------+----------+'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.cuda(), dummy_input.cuda(), device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
