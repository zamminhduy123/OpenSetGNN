{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d403db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('/home/ntmduy/GraphAE/src/model')))\n",
    "sys.path.append(os.path.join(os.path.dirname('/home/ntmduy/GraphAE/src/utils')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "016f6f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.GAE_Projection_Att import GAE_CLS_Link_NODE_Cosine_SupCon_2\n",
    "from model.resnet_big import SupCEResNet, SupConResNet, LinearClassifier, SupIncepResnet\n",
    "import torch\n",
    "from torch_geometric.nn import summary\n",
    "from thop import profile\n",
    "import numpy as np\n",
    "import time\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils.data import load_and_split_graphs\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.nn.functional as F\n",
    "from thop import profile as thopprofile, clever_format\n",
    "from torch_geometric.utils import to_dense_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519af486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a2b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_gpu(dummy_input, model, device, rep, none_gnn=False):\n",
    "    model = model.to(device=device)\n",
    "    # dummy_input = torch.randn(1, 1, 29, 29, dtype=torch.float).to(device)\n",
    "    # INIT LOGGERS\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = rep\n",
    "    timings=np.zeros((repetitions,1))\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(100):\n",
    "        if (none_gnn):\n",
    "            _ = model(dummy_input)\n",
    "        else:\n",
    "            _ = model(dummy_input, device, acummulate = True, remove_random=True)\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            starter.record()\n",
    "            if (none_gnn):\n",
    "                _ = model(dummy_input)\n",
    "            else:\n",
    "                _ = model(dummy_input, device, acummulate = True, remove_random=True)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0966f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_cpu(model, device, rep = 10):\n",
    "    model = model.to(device=device)\n",
    "    x = torch.rand((1, 1, 29, 29), device=device)\n",
    "    timings=np.zeros((rep,1))\n",
    "    for i in range(rep):    \n",
    "        start_time = time.time()\n",
    "        out = model(x)\n",
    "        timings[i] = time.time() - start_time\n",
    "    mean_syn = np.sum(timings) / rep\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee739c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_graph_reconstruction_loss(reconstructed, original, batch_index, reduced=\"mean\"):\n",
    "    \"\"\"\n",
    "    Calculate the mean reconstruction loss for each graph in a batch.\n",
    "    \n",
    "    Args:\n",
    "        reconstructed (torch.Tensor): Reconstructed node features, shape [num_nodes, num_features].\n",
    "        original (torch.Tensor): Original node features, shape [num_nodes, num_features].\n",
    "        batch_index (torch.Tensor): Batch indices mapping each node to a graph, shape [num_nodes].\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Mean reconstruction loss for each graph, shape [num_graphs].\n",
    "    \"\"\"\n",
    "    # Calculate MSE loss for each node\n",
    "    node_mse_loss = torch.mean((reconstructed - original) ** 2, dim=1)  # Shape: [num_nodes]\n",
    "\n",
    "    # Aggregate losses for each graph\n",
    "    num_graphs = batch_index.max().item() + 1  # Total number of graphs in the batch\n",
    "    graph_losses = torch.zeros(num_graphs, device=reconstructed.device)  # Initialize graph loss storage\n",
    "\n",
    "    for graph_id in range(num_graphs):\n",
    "        # Mask to select nodes belonging to the current graph\n",
    "        graph_mask = (batch_index == graph_id)\n",
    "        \n",
    "        # Mean MSE loss for the current graph\n",
    "        if (reduced == \"mean\"):\n",
    "            graph_losses[graph_id] = torch.mean(node_mse_loss[graph_mask])\n",
    "        elif (reduced == \"none\"):\n",
    "            return graph_losses\n",
    "        else:\n",
    "            graph_losses[graph_id] = sum(node_mse_loss[graph_mask])\n",
    "    return graph_losses\n",
    "\n",
    "def open_set_inference_optimized(ae_model,\n",
    "                                 batch,\n",
    "                                 thresholds,\n",
    "                                 class_centers=None,\n",
    "                                 device='cuda',\n",
    "                                 num_known_classes=None): # Add num_known_classes\n",
    "    \"\"\"\n",
    "    Optimized forward pass for open-set inference.\n",
    "    \"\"\"\n",
    "    ae_model.eval()\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # --- Model Forward Pass (No changes here, assumed to be optimized within ae_model) ---\n",
    "    with torch.no_grad():\n",
    "        M_sup = ae_model(batch, device, acummulate=True, remove_random=True)\n",
    "        graph_emb_sup = ae_model.graph_embedding(M_sup, batch.batch)\n",
    "        graph_emb_sup = F.normalize(graph_emb_sup, p=2, dim=1) # [B, EmbDim]\n",
    "\n",
    "        # Calculate distances to all class centers\n",
    "        dists = torch.cdist(graph_emb_sup, class_centers, p=2) # [B, C_known]\n",
    "        logits = -dists\n",
    "        probs = F.softmax(logits, dim=1) # [B, C_known]\n",
    "        max_probs, pred_cls_known = probs.max(dim=1) # max_probs and indices for known classes\n",
    "\n",
    "        # Reconstruction\n",
    "        # Adjacency reconstruction loss (graph-level)\n",
    "        adj_rec = ae_model.adj_decode(M_sup, batch.batch, use_sigmoid=False)\n",
    "        adj_ori = to_dense_adj(batch.edge_index,\n",
    "                               batch.batch,\n",
    "                               edge_attr=batch.edge_attr[:, 0].unsqueeze(1) if batch.edge_attr is not None else None).squeeze(3)\n",
    "        # Ensure adj_rec and adj_ori have compatible shapes for mse_loss\n",
    "        # This might require padding or careful handling if graph sizes vary significantly\n",
    "        # and ae_model.adj_decode doesn't produce consistently sized outputs per graph\n",
    "        # For now, assuming they are compatible or loss handles it.\n",
    "        adj_loss = F.mse_loss(adj_rec, adj_ori, reduction='none').sum(dim=(1, 2)) # [B]\n",
    "\n",
    "        # Node reconstruction loss (graph-level)\n",
    "        node_hat = ae_model.node_recon(M_sup)\n",
    "        node_rec_loss = calculate_graph_reconstruction_loss(node_hat, batch.x, batch.batch, reduced=\"sum\") # [B]\n",
    "\n",
    "    # --- Open-Set Logic (Vectorized) ---\n",
    "    num_graphs_in_batch = graph_emb_sup.size(0)\n",
    "    if num_known_classes is None and class_centers is not None:\n",
    "        num_known_classes = class_centers.size(0)\n",
    "    elif num_known_classes is None:\n",
    "        raise ValueError(\"num_known_classes must be provided if class_centers is None or for unknown label assignment\")\n",
    "\n",
    "    # Initialize predictions as the predicted known class\n",
    "    pred_out = pred_cls_known.clone() # [B]\n",
    "\n",
    "    # Rule 1: Distance to predicted class center > its threshold (vectorized)\n",
    "    # Gather the specific distance thresholds for each predicted class\n",
    "    # thresholds['distance'] is expected to be a tensor or list of length C_known\n",
    "    distance_thresholds_for_pred_cls = torch.tensor(thresholds['distance'], device=device)[pred_cls_known] # [B]\n",
    "    distances_to_pred_cls = dists.gather(1, pred_cls_known.unsqueeze(1)).squeeze(1) # [B]\n",
    "    unknown_due_to_distance_to_pred = (distances_to_pred_cls > distance_thresholds_for_pred_cls) # [B]\n",
    "\n",
    "    # Initialize reasons (0: benign, 1: known_attack, >1: unknown due to specific anomaly)\n",
    "    reasons = torch.zeros(num_graphs_in_batch, dtype=torch.long, device=device)\n",
    "    reasons[pred_cls_known > 0] = 1 # Mark known attacks (assuming class 0 is benign)\n",
    "\n",
    "    # SVDD distance for benign class (class 0)\n",
    "    d_svdd_benign = dists[:, 0] # [B]\n",
    "\n",
    "    # Identify samples initially predicted as benign (class 0) OR\n",
    "    # those that already violated their predicted class's distance threshold\n",
    "    # These are candidates for being re-classified as 'unknown' based on anomaly metrics\n",
    "    # or staying benign if they pass all checks.\n",
    "    benign_candidates_mask = (pred_cls_known == 0) | unknown_due_to_distance_to_pred # [B]\n",
    "\n",
    "    # --- Anomaly checks for benign_candidates_mask ---\n",
    "    # These flags are only relevant for samples in benign_candidates_mask\n",
    "    adj_flag_all = (adj_loss > thresholds['adj']) # [B]\n",
    "    node_flag_all = (node_rec_loss > thresholds['node']) # [B]\n",
    "    svdd_flag_all = (d_svdd_benign > thresholds['distance'][0]) # [B], distance to benign center threshold\n",
    "\n",
    "    # Combine flags for reason codes (only for benign candidates)\n",
    "    # We apply the benign_candidates_mask *after* calculating all flags to keep indexing simple\n",
    "    adj_flag_bc = adj_flag_all[benign_candidates_mask]\n",
    "    node_flag_bc = node_flag_all[benign_candidates_mask]\n",
    "    svdd_flag_bc = svdd_flag_all[benign_candidates_mask]\n",
    "\n",
    "    # Calculate reason codes for the benign candidates subset\n",
    "    flag_combo_bc = (adj_flag_bc.long() * 1 +\n",
    "                     node_flag_bc.long() * 2 +\n",
    "                     svdd_flag_bc.long() * 4) # yields 0-7 for benign candidates\n",
    "\n",
    "    # Map combo to final reason codes (2-8 for anomalies, 0 if still benign)\n",
    "    # combo_to_reason_map_tensor should be precomputed and on the correct device\n",
    "    # For example:\n",
    "    # _combo_map = {0:0, 1:2, 2:3, 3:5, 4:4, 5:6, 6:7, 7:8}     0 means stays benign/known attack\n",
    "    # combo_to_reason_map_tensor = torch.tensor([_combo_map[i] for i in range(8)], device=device)\n",
    "    # Optimized: Create this map directly\n",
    "    combo_to_reason_map_tensor = torch.tensor([0, 2, 3, 5, 4, 6, 7, 8], device=device, dtype=torch.long)\n",
    "    reasons_for_benign_candidates = combo_to_reason_map_tensor[flag_combo_bc]\n",
    "\n",
    "    # Update reasons for those initially benign candidates\n",
    "    # If reasons_for_benign_candidates > 0, it means it's an anomaly type\n",
    "    reasons[benign_candidates_mask] = torch.where(\n",
    "        reasons_for_benign_candidates > 0, # If an anomaly reason code was generated\n",
    "        reasons_for_benign_candidates,     # Use that anomaly reason\n",
    "        reasons[benign_candidates_mask]    # Otherwise, keep original reason (0 for benign, 1 for known attack if it was a misclassified known that passed distance)\n",
    "    )\n",
    "\n",
    "    # Samples become 'unknown' if:\n",
    "    # 1. They were benign_candidates AND any of their anomaly flags (adj, node, svdd for benign) were true\n",
    "    # 2. OR they initially violated their predicted class's distance threshold (unknown_due_to_distance_to_pred)\n",
    "    is_unknown_anomaly = (benign_candidates_mask & ( (adj_flag_all | node_flag_all | svdd_flag_all)[benign_candidates_mask] )) \\\n",
    "                       | unknown_due_to_distance_to_pred\n",
    "\n",
    "    pred_out[is_unknown_anomaly] = num_known_classes # Assign 'unknown' label (e.g., C_known if labels are 0 to C_known-1)\n",
    "\n",
    "    # Ensure pred_out for samples that are not unknown, but were initially marked as known attacks (>0),\n",
    "    # and did NOT violate distance_to_pred, retain their known attack label.\n",
    "    # This is implicitly handled as pred_out is initialized with pred_cls_known.\n",
    "    # We only overwrite with 'unknown' or keep benign/known_attack.\n",
    "\n",
    "    return pred_out.cpu().numpy(), reasons.cpu().numpy(), \\\n",
    "           d_svdd_benign.cpu(), adj_loss.cpu(), node_rec_loss.cpu(), \\\n",
    "           graph_emb_sup # graph_emb_sup is already on device, return as is or move to cpu() if needed by caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a8d7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_set_inference(ae_model,\n",
    "                       batch,\n",
    "                       thresholds,\n",
    "                       class_centers=None,\n",
    "                       device='cuda',\n",
    "                       num_classes = 5):\n",
    "    ae_model.eval()\n",
    "\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        M_sup = ae_model(batch, device, acummulate=True, remove_random=True)\n",
    "        graph_emb_sup = ae_model.graph_embedding(M_sup, batch.batch)\n",
    "        graph_emb_sup = F.normalize(graph_emb_sup, p=2, dim=1)\n",
    "        \n",
    "        # features = ae_model.graph_pooling(M_sup, batch.batch)\n",
    "        dists = torch.cdist(graph_emb_sup, class_centers, p=2) # [B, C_known]\n",
    "        logits = -dists\n",
    "\n",
    "        probs  = F.softmax(logits, dim=1)        # [B, C_known]\n",
    "        _, pred_cls = probs.max(dim=1)\n",
    "\n",
    "        # recon\n",
    "        adj_rec  = ae_model.adj_decode(M_sup, batch.batch, use_sigmoid=False)\n",
    "        node_hat = ae_model.node_recon(M_sup)\n",
    "        adj_ori  = to_dense_adj(batch.edge_index,\n",
    "                                batch.batch,\n",
    "                                edge_attr=batch.edge_attr[:, 0].unsqueeze(1)).squeeze(3)\n",
    "        adj_loss = F.mse_loss(adj_rec, adj_ori, reduction='none').sum(dim=(1,2))\n",
    "\n",
    "        rec_loss = calculate_graph_reconstruction_loss(node_hat, batch.x, batch.batch, reduced=\"sum\")\n",
    "\n",
    "    # 1) For each sample, find the closest class center and check against its threshold\n",
    "    pred_out = pred_cls.cpu().numpy()              # 0 = benign, >0 = known attack\n",
    "\n",
    "    unknown_distance = []\n",
    "    for i in range(len(pred_out)):\n",
    "        unknown_distance.append(False)\n",
    "        distance = dists[i, pred_out[i]].item()  # distance to the predicted class center\n",
    "        if (distance > thresholds['distance'][pred_out[i]]):\n",
    "            unknown_distance[i] = True\n",
    "    unknown_distance = torch.tensor(unknown_distance).to(device)\n",
    "   \n",
    "    pred_benign_mask = torch.logical_or(pred_cls == 0, unknown_distance)   # apply distance check\n",
    "    reasons = np.zeros_like(pred_out)          # default benign\n",
    "    reasons[pred_cls.cpu().numpy() > 0] = 1    # known attack\n",
    "\n",
    "    d_svdd = dists[:, 0].cpu()\n",
    "\n",
    "    # -------------------------------------------------------- #\n",
    "    #  Build reason codes for benign‑predicted subset\n",
    "    #    2  = adj only\n",
    "    #    3  = node only\n",
    "    #    4  = svdd only\n",
    "    #    5  = adj + node\n",
    "    #    6  = adj + svdd\n",
    "    #    7  = node + svdd\n",
    "    #    8  = adj + node + svdd\n",
    "    # -------------------------------------------------------- \n",
    "\n",
    "    if pred_benign_mask.any():\n",
    "        # --- evaluate anomaly metrics ONLY for those benign-predicted graphs ---\n",
    "        idx_benign = pred_benign_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "        # (a) reconstruction & SVDD for that subset\n",
    "        adj_flag   = adj_loss[idx_benign].cpu()  > thresholds['adj']\n",
    "        node_flag  = rec_loss[idx_benign].cpu() > thresholds['node']\n",
    "        svdd_flag  = dists[idx_benign, 0].cpu() > thresholds['distance'][0]\n",
    "\n",
    "        flag_combo = adj_flag.to(torch.int) * 1 \\\n",
    "                + node_flag.to(torch.int) * 2  \\\n",
    "                + svdd_flag.to(torch.int) * 4 # yields 0‑7\n",
    "        combo_to_reason = {1:2, 2:3, 3:5,\n",
    "                            4:4, 5:6, 6:7,\n",
    "                            7:8}\n",
    "        for local_idx, combo in enumerate(flag_combo.cpu().numpy()):\n",
    "            if combo == 0:\n",
    "                continue\n",
    "            global_idx = idx_benign[local_idx].cpu().item()\n",
    "            reasons[global_idx] = combo_to_reason[combo]\n",
    "\n",
    "        # (b) If ANY metric says “anomaly” → flip to “unknown”\n",
    "        unknown_idx = idx_benign[(adj_flag | node_flag | svdd_flag)]\n",
    "\n",
    "        # write label = NUM_CLASSES  for those graphs\n",
    "        pred_out[unknown_idx.cpu().numpy()] = num_classes   # label for unknown attack\n",
    "\n",
    "    return pred_out, reasons, torch.tensor(d_svdd), adj_loss, rec_loss, graph_emb_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "854217cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(model, test_loader, device='cuda', num_warmup=10, num_repeats=100, num_classes =5):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        print(f\"Warming up for {num_warmup} iterations...\")\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            open_set_inference(model, \n",
    "                                         batch, \n",
    "                                         thresholds={'distance': [0.5]*num_classes, 'adj': 0.1, 'node': 0.1}, \n",
    "                                         device=device,\n",
    "                                         class_centers=torch.zeros((num_classes, 128), device=device), \n",
    "                                         num_classes=num_classes)\n",
    "            if i >= num_warmup - 1:\n",
    "                break\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Starting timed inference over {num_repeats} iterations...\")\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= num_repeats:\n",
    "                break\n",
    "            batch = batch.to(device)\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.perf_counter()\n",
    "            open_set_inference(model, \n",
    "                                batch, \n",
    "                                thresholds={'distance': [0.5]*num_classes, 'adj': 0.1, 'node': 0.1}, \n",
    "                                device=device,\n",
    "                                class_centers=torch.zeros((num_classes, 128), device=device), \n",
    "                                num_classes=num_classes)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.perf_counter()\n",
    "            times.append(end_time - start_time)\n",
    "\n",
    "        times = np.array(times)\n",
    "        print(f\"Tested {len(times)} samples.\")\n",
    "        print(f\"Mean Latency: {np.mean(times)*1000:.2f} ms\")\n",
    "        print(f\"Median Latency: {np.median(times)*1000:.2f} ms\")\n",
    "        print(f\"Throughput: {1/np.mean(times):.2f} samples/sec\")\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "            print(f\"Max GPU memory used: {mem:.2f} MB\")\n",
    "            torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215aaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'/home/ntmduy/GraphAE/data/mas/WS_300/step_300/9/edge_features_3/normalized_except_id/raw/sort_seperated'\n",
    "\n",
    "train_graphs, test_graphs, graphs_names = load_and_split_graphs(path, exclude=[], train_ratio=0.8, seed=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1314d766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3976940/560639031.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  graph.edge_attr = torch.tensor(graph.edge_attr[:, 0].reshape(-1, 1), dtype=torch.float32)\n",
      "/tmp/ipykernel_3976940/560639031.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input.edge_attr = torch.tensor(dummy_input.edge_attr[:, 0].reshape(-1, 1), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "warmup_loader = DataLoader([train_graphs[0]], batch_size=1, shuffle=False)\n",
    "\n",
    "for graph in test_graphs:\n",
    "    graph.edge_attr = torch.tensor(graph.edge_attr[:, 0].reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "test_loader = DataLoader(test_graphs, batch_size=1, shuffle=False)\n",
    "\n",
    "dummy_input = next(iter(warmup_loader)).to('cuda')\n",
    "dummy_input.edge_attr = torch.tensor(dummy_input.edge_attr[:, 0].reshape(-1, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46194556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(np.unique([g.y for g in train_graphs]))\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a467ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.946622718334198, 0.3170323983073103)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAE_CLS_Link_NODE_Cosine_SupCon_2(num_features=9, embedding_size=32, projection_emb=128, activate='gelu', layer_type='gatv2', num_layers=2, directed=False, id_dim=1, num_classes = NUM_CLASSES, linear_node=True, num_id_embeddings=2048, attn_head=1)\n",
    "measure_time_gpu(dummy_input, model, 'cuda', rep=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98e4d174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.271770525932312, 0.13737580240076167)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incep = SupIncepResnet(num_classes=NUM_CLASSES)\n",
    "measure_time_gpu(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(), incep, 'cuda', rep=1000, none_gnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f4d65e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.411258074402809, 0.875621319126651)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supcon = SupCEResNet(name='resnet18', num_classes=NUM_CLASSES)\n",
    "measure_time_gpu(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(), supcon, 'cuda', rep=1000, none_gnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa9169f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up for 10 iterations...\n",
      "Starting timed inference over 100 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3976940/217683769.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return pred_out, reasons, torch.tensor(d_svdd), adj_loss, rec_loss, graph_emb_sup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 100 samples.\n",
      "Mean Latency: 8.73 ms\n",
      "Median Latency: 8.67 ms\n",
      "Throughput: 114.49 samples/sec\n",
      "Max GPU memory used: 144.56 MB\n"
     ]
    }
   ],
   "source": [
    "analyze_performance(model, test_loader, device='cuda', num_warmup=10, num_repeats=100, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30a05d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gnn_model(model, example_data, device=None, repeat=10):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device).eval()\n",
    "    example_data = example_data.to(device)\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                 record_shapes=True,\n",
    "                 profile_memory=True,\n",
    "                 with_flops=True) as prof:\n",
    "        with torch.no_grad():\n",
    "            for _ in range(repeat):\n",
    "                with record_function(\"model_inference\"):\n",
    "                    model(example_data)\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=15))\n",
    "    print(prof.key_averages().table(sort_by=\"flops\", row_limit=15))\n",
    "    # For total FLOPs (note: double to get MACs for real-valued ops)\n",
    "    total_flops = sum([item.flops for item in prof.key_averages() if hasattr(item, 'flops')])\n",
    "    print(f'Estimated total FLOPs: {clever_format([total_flops], \"%.3f\")}')\n",
    "    print(f'Estimated total MACs: {(total_flops/2)} {clever_format([total_flops/2], \"%.3f\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fba16d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-06-06 10:46:42 3976940:3976940 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-06-06 10:46:42 3976940:3976940 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-06-06 10:46:42 3976940:3976940 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                aten::cudnn_convolution        17.58%      11.820ms        25.63%      17.234ms      86.170us       1.408ms        74.58%       1.408ms       7.040us           0 b           0 b       5.15 Mb       5.15 Mb           200            --  \n",
      "sm86_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f3...         0.00%       0.000us         0.00%       0.000us       0.000us     359.000us        19.01%     359.000us       5.983us           0 b           0 b           0 b           0 b            60            --  \n",
      "cudnn_infer_ampere_scudnn_winograd_128x128_ldg1_ldg4...         0.00%       0.000us         0.00%       0.000us       0.000us     340.000us        18.01%     340.000us       4.857us           0 b           0 b           0 b           0 b            70            --  \n",
      "sm86_xmma_fprop_implicit_gemm_tf32f32_tf32f32_f32_nh...         0.00%       0.000us         0.00%       0.000us       0.000us     339.000us        17.96%     339.000us      11.300us           0 b           0 b           0 b           0 b            30            --  \n",
      "                                 aten::cudnn_batch_norm        11.17%       7.514ms        24.38%      16.397ms      81.985us     201.000us        10.65%     201.000us       1.005us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "void cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float,...         0.00%       0.000us         0.00%       0.000us       0.000us     201.000us        10.65%     201.000us       1.005us           0 b           0 b           0 b           0 b           200            --  \n",
      "void cudnn::ops::nchwToNhwcKernel<float, float, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     190.000us        10.06%     190.000us       1.056us           0 b           0 b           0 b           0 b           180            --  \n",
      "                                        aten::clamp_min         4.06%       2.731ms         6.03%       4.053ms      23.841us     170.000us         9.00%     170.000us       1.000us           0 b           0 b       4.64 Mb       4.64 Mb           170            --  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     170.000us         9.00%     170.000us       1.000us           0 b           0 b           0 b           0 b           170            --  \n",
      "void implicit_convolve_sgemm<float, float, 128, 5, 5...         0.00%       0.000us         0.00%       0.000us       0.000us     110.000us         5.83%     110.000us       2.750us           0 b           0 b           0 b           0 b            40            --  \n",
      "                                             aten::add_         1.67%       1.123ms         2.58%       1.736ms      21.700us      79.000us         4.18%      79.000us       0.988us           0 b           0 b           0 b           0 b            80            --  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      79.000us         4.18%      79.000us       0.988us           0 b           0 b           0 b           0 b            80            --  \n",
      "void cudnn::winograd::generateWinogradTilesKernel<0,...         0.00%       0.000us         0.00%       0.000us       0.000us      70.000us         3.71%      70.000us       1.000us           0 b           0 b           0 b           0 b            70            --  \n",
      "                                             aten::mean         0.41%     275.000us         0.56%     379.000us      37.900us      20.000us         1.06%      20.000us       2.000us           0 b           0 b       5.00 Kb       5.00 Kb            10            --  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      20.000us         1.06%      20.000us       2.000us           0 b           0 b           0 b           0 b            10            --  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 67.243ms\n",
      "Self CUDA time total: 1.888ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::conv2d         1.69%       1.137ms        31.90%      21.453ms     107.265us       0.000us         0.00%       1.406ms       7.030us           0 b           0 b       5.15 Mb      45.00 Kb           200    640435.520  \n",
      "                                            aten::addmm         0.68%     456.000us         0.85%     570.000us      57.000us      10.000us         0.53%      10.000us       1.000us           0 b           0 b       5.00 Kb       5.00 Kb            10        15.360  \n",
      "                                        model_inference        28.74%      19.323ms        99.94%      67.200ms       6.720ms       0.000us         0.00%       1.888ms     188.800us           0 b           0 b           0 b     -15.00 Mb            10            --  \n",
      "                                      aten::convolution         2.22%       1.492ms        30.20%      20.306ms     101.530us       0.000us         0.00%       1.395ms       6.975us           0 b           0 b       5.15 Mb       8.00 Kb           200            --  \n",
      "                                     aten::_convolution         2.47%       1.664ms        28.10%      18.898ms      94.490us       0.000us         0.00%       1.408ms       7.040us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                                aten::cudnn_convolution        17.58%      11.820ms        25.63%      17.234ms      86.170us       1.408ms        74.58%       1.408ms       7.040us           0 b           0 b       5.15 Mb       5.15 Mb           200            --  \n",
      "                                        cudaEventRecord         0.89%     596.000us         0.89%     596.000us       1.490us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           400            --  \n",
      "                                  cudaStreamIsCapturing         0.05%      31.000us         0.05%      31.000us       0.077us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           400            --  \n",
      "                                  cudaStreamGetPriority         0.01%       6.000us         0.01%       6.000us       0.015us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           400            --  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.01%       4.000us         0.01%       4.000us       0.010us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           400            --  \n",
      "                                       cudaLaunchKernel        12.03%       8.087ms        12.03%       8.087ms       9.743us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           830            --  \n",
      "void implicit_convolve_sgemm<float, float, 128, 5, 5...         0.00%       0.000us         0.00%       0.000us       0.000us     110.000us         5.83%     110.000us       2.750us           0 b           0 b           0 b           0 b            40            --  \n",
      "                                       aten::batch_norm         1.00%     674.000us        26.96%      18.130ms      90.650us       0.000us         0.00%     201.000us       1.005us           0 b           0 b       5.15 Mb     -16.00 Kb           200            --  \n",
      "                           aten::_batch_norm_impl_index         1.57%       1.059ms        25.84%      17.376ms      86.880us       0.000us         0.00%     200.000us       1.000us           0 b           0 b       5.15 Mb      16.00 Kb           200            --  \n",
      "                                 aten::cudnn_batch_norm        11.17%       7.514ms        24.38%      16.397ms      81.985us     201.000us        10.65%     201.000us       1.005us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 67.243ms\n",
      "Self CUDA time total: 1.888ms\n",
      "\n",
      "Estimated total FLOPs: 640.451M\n",
      "Estimated total MACs: 320225440.0 320.225M\n"
     ]
    }
   ],
   "source": [
    "profile_gnn_model(supcon.to(device='cpu'), torch.randn(1, 1, 29, 29, dtype=torch.float).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecb460ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-06-06 10:46:49 3976940:3976940 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-06-06 10:46:49 3976940:3976940 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-06-06 10:46:49 3976940:3976940 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::copy_         4.12%       9.892ms        59.50%     142.954ms     137.192us     681.000us        39.14%     681.000us       0.654us           0 b           0 b           0 b           0 b          1042            --  \n",
      "                       Memcpy DtoH (Device -> Pageable)         0.00%       0.000us         0.00%       0.000us       0.000us     451.000us        25.92%     451.000us       0.848us           0 b           0 b           0 b           0 b           532            --  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     223.000us        12.82%     223.000us       0.446us           0 b           0 b           0 b           0 b           500            --  \n",
      "                                     aten::scatter_add_         1.03%       2.478ms         1.45%       3.490ms      29.083us     181.000us        10.40%     181.000us       1.508us           0 b           0 b           0 b           0 b           120            --  \n",
      "void at::native::_scatter_gather_elementwise_kernel<...         0.00%       0.000us         0.00%       0.000us       0.000us     181.000us        10.40%     181.000us       1.508us           0 b           0 b           0 b           0 b           120            --  \n",
      "                                            aten::addmm         0.67%       1.605ms         0.98%       2.347ms      58.675us     155.000us         8.91%     155.000us       3.875us           0 b           0 b     360.00 Kb     360.00 Kb            40      3778.560  \n",
      "                                     aten::index_select         1.23%       2.952ms         2.60%       6.247ms      44.621us     145.000us         8.33%     145.000us       1.036us           0 b           0 b       1.39 Mb           0 b           140            --  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     105.000us         6.03%     105.000us       1.050us           0 b           0 b           0 b           0 b           100            --  \n",
      "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      96.000us         5.52%      96.000us       2.400us           0 b           0 b           0 b           0 b            40            --  \n",
      "                                              aten::add         0.93%       2.234ms         1.30%       3.135ms      26.125us      95.000us         5.46%      95.000us       0.792us           0 b           0 b       1.04 Mb       1.04 Mb           120       268.320  \n",
      "                                              aten::mul         0.80%       1.918ms         1.13%       2.711ms      27.110us      95.000us         5.46%      95.000us       0.950us           0 b           0 b       1.19 Mb       1.19 Mb           100       266.880  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      80.000us         4.60%      80.000us       1.000us           0 b           0 b           0 b           0 b            80            --  \n",
      "                                              aten::div         0.57%       1.366ms         0.82%       1.977ms      24.712us      80.000us         4.60%      80.000us       1.000us           0 b           0 b     220.00 Kb     220.00 Kb            80            --  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      70.000us         4.02%      70.000us       0.778us           0 b           0 b           0 b           0 b            90            --  \n",
      "void splitKreduce_kernel<32, 16, int, float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us      59.000us         3.39%      59.000us       1.475us           0 b           0 b           0 b           0 b            40            --  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 240.271ms\n",
      "Self CUDA time total: 1.740ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm         0.67%       1.605ms         0.98%       2.347ms      58.675us     155.000us         8.91%     155.000us       3.875us           0 b           0 b     360.00 Kb     360.00 Kb            40      3778.560  \n",
      "                                              aten::add         0.93%       2.234ms         1.30%       3.135ms      26.125us      95.000us         5.46%      95.000us       0.792us           0 b           0 b       1.04 Mb       1.04 Mb           120       268.320  \n",
      "                                              aten::mul         0.80%       1.918ms         1.13%       2.711ms      27.110us      95.000us         5.46%      95.000us       0.950us           0 b           0 b       1.19 Mb       1.19 Mb           100       266.880  \n",
      "                                               aten::mm         0.24%     577.000us         0.31%     755.000us      37.750us      20.000us         1.15%      20.000us       1.000us           0 b           0 b     340.00 Kb     340.00 Kb            20       174.080  \n",
      "                                        model_inference        15.32%      36.798ms        99.66%     239.452ms      23.945ms       0.000us         0.00%       1.740ms     174.000us     271.26 Kb    -126.92 Kb    -279.00 Kb      -6.61 Mb            10            --  \n",
      "                                               aten::to         2.63%       6.313ms        65.96%     158.484ms     114.843us       0.000us         0.00%     664.000us       0.481us     396.11 Kb       2.08 Kb     340.00 Kb       6.50 Kb          1380            --  \n",
      "                                         aten::_to_copy         3.14%       7.549ms        64.86%     155.841ms     151.009us       0.000us         0.00%     671.000us       0.650us     396.11 Kb       3.23 Kb     340.00 Kb           0 b          1032            --  \n",
      "                                    aten::empty_strided         2.40%       5.764ms         2.40%       5.764ms       5.532us       0.000us         0.00%       0.000us       0.000us     392.88 Kb     392.88 Kb     430.00 Kb     430.00 Kb          1042            --  \n",
      "                                            aten::copy_         4.12%       9.892ms        59.50%     142.954ms     137.192us     681.000us        39.14%     681.000us       0.654us           0 b           0 b           0 b           0 b          1042            --  \n",
      "                                        cudaMemcpyAsync         5.74%      13.787ms         5.74%      13.787ms      13.231us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1042            --  \n",
      "                       Memcpy DtoH (Device -> Pageable)         0.00%       0.000us         0.00%       0.000us       0.000us     451.000us        25.92%     451.000us       0.848us           0 b           0 b           0 b           0 b           532            --  \n",
      "                                  cudaStreamSynchronize        49.64%     119.275ms        49.64%     119.275ms     115.577us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1032            --  \n",
      "                aten::_has_compatible_shallow_copy_type         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1180            --  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     223.000us        12.82%     223.000us       0.446us           0 b           0 b           0 b           0 b           500            --  \n",
      "                                           aten::linear         0.22%     539.000us         1.84%       4.422ms      73.700us       0.000us         0.00%     175.000us       2.917us           0 b           0 b     700.00 Kb           0 b            60            --  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 240.271ms\n",
      "Self CUDA time total: 1.740ms\n",
      "\n",
      "Estimated total FLOPs: 4.488M\n",
      "Estimated total MACs: 2243920.0 2.244M\n"
     ]
    }
   ],
   "source": [
    "dummy_input = dummy_input.to(device='cpu')\n",
    "model = model.to(device='cpu')\n",
    "profile_gnn_model(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47bd1543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 97.191M\n",
      "Params: 1.695M\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(incep, inputs=(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(),), verbose=False)\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bcf8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 32.561M\n",
      "Params: 700.662K\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(supcon, inputs=(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(),), verbose=False)\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48100a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 0.0\n",
      "Params: 0.0\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(model, inputs=(dummy_input,), verbose=False)\n",
    "\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89fc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+-----------------------------------+------------------------------+-------------------------------+----------+\\n| Layer                             | Input Shape                  | Output Shape                  | #Param   |\\n|-----------------------------------+------------------------------+-------------------------------+----------|\\n| GAE_CLS_Link_NODE_Cosine_SupCon_2 | [72, 72]                     | [72, 32]                      | 74,715   |\\n| ├─(id_embedding)Embedding         | --                           | --                            | 2,048    |\\n| ├─(encoder)Graph_Encoder_Norm     | [72, 9], [2, 136], [136, 1]  | [72, 32], [72, 32], [2304, 2] | 3,154    |\\n| │    └─(bn)BatchNorm1d            | --                           | --                            | 18       |\\n| │    └─(convs)ModuleList          | --                           | --                            | 2,944    |\\n| │    │    └─(0)GATv2Conv          | [72, 9], [2, 136], [136, 1]  | [72, 32]                      | 736      |\\n| │    │    └─(1)GATv2Conv          | [72, 32], [2, 136], [136, 1] | [72, 32]                      | 2,208    |\\n| │    └─(norms)ModuleList          | --                           | --                            | 192      |\\n| │    │    └─(0)GraphNorm          | [72, 32]                     | [72, 32]                      | 96       |\\n| │    │    └─(1)GraphNorm          | [72, 32]                     | [72, 32]                      | 96       |\\n| │    └─(activate_function)GELU    | [72, 32]                     | [72, 32]                      | --       |\\n| ├─(linear)Sequential              | --                           | --                            | 24,832   |\\n| │    └─(0)Linear                  | --                           | --                            | 8,320    |\\n| │    └─(1)GELU                    | --                           | --                            | --       |\\n| │    └─(2)Dropout                 | --                           | --                            | --       |\\n| │    └─(3)Linear                  | --                           | --                            | 16,512   |\\n| ├─(read_out)Set2Set               | --                           | --                            | 20,992   |\\n| │    └─(lstm)LSTM                 | --                           | --                            | 20,992   |\\n| ├─(decoder)MLPDecoder             | --                           | --                            | 21,513   |\\n| │    └─(mlp)Sequential            | --                           | --                            | 21,513   |\\n| │    │    └─(0)Linear             | --                           | --                            | 16,896   |\\n| │    │    └─(1)ReLU               | --                           | --                            | --       |\\n| │    │    └─(2)Linear             | --                           | --                            | 4,617    |\\n| ├─(node_out_1)Linear              | --                           | --                            | 1,056    |\\n| ├─(node_out_2)Linear              | --                           | --                            | 1,056    |\\n+-----------------------------------+------------------------------+-------------------------------+----------+'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.cuda(), dummy_input.cuda(), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393dc5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
