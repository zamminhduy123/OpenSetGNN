{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d403db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('/home/dhkim/OpenSetGNN-main/src/model')))\n",
    "sys.path.append(os.path.join(os.path.dirname('/home/dhkim/OpenSetGNN-main/src/utils')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3f36db-a262-4e8c-a003-6f512e4898f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim/pyg_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.12.0a0+2c916ef.nv22.3\n",
      "PyTorch CUDA Version: 11.4\n",
      "CUDA available: True\n",
      "TorchVision Version: 0.13.0a0+da3794e\n",
      "PyTorch Geometric Version: 2.1.0\n",
      "Torch-scatter Version: 2.1.1\n",
      "Torch-sparse Version: 0.6.15\n",
      "Torch-cluster Version: 1.6.1\n",
      "Tensor on CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import torch_cluster\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"PyTorch CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"TorchVision Version: {torchvision.__version__}\")\n",
    "print(f\"PyTorch Geometric Version: {torch_geometric.__version__}\")\n",
    "print(f\"Torch-scatter Version: {torch_scatter.__version__}\")\n",
    "print(f\"Torch-sparse Version: {torch_sparse.__version__}\")\n",
    "print(f\"Torch-cluster Version: {torch_cluster.__version__}\")\n",
    "\n",
    "# Simple CUDA test\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.randn(5, 5).cuda()\n",
    "    print(f\"Tensor on CUDA: {x.is_cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016f6f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.GAE_Projection_Att import GAE_CLS_Link_NODE_Cosine_SupCon_2\n",
    "from model.resnet_big import SupCEResNet, SupConResNet, LinearClassifier, SupIncepResnet\n",
    "import torch\n",
    "# from torch_geometric.nn import summary\n",
    "from thop import profile\n",
    "import numpy as np\n",
    "import time\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.nn.functional as F\n",
    "from thop import profile as thopprofile, clever_format\n",
    "from torch_geometric.utils import to_dense_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a6e8a-f0f7-488d-9645-5149969635d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519af486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a2b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_gpu(dummy_input, model, device, rep, none_gnn=False):\n",
    "    model = model.to(device=device)\n",
    "    # dummy_input = torch.randn(1, 1, 29, 29, dtype=torch.float).to(device)\n",
    "    # INIT LOGGERS\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = rep\n",
    "    timings=np.zeros((repetitions,1))\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(100):\n",
    "        if (none_gnn):\n",
    "            _ = model(dummy_input)\n",
    "        else:\n",
    "            _ = model(dummy_input, device, acummulate = True, remove_random=True)\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            starter.record()\n",
    "            if (none_gnn):\n",
    "                _ = model(dummy_input)\n",
    "            else:\n",
    "                _ = model(dummy_input, device, acummulate = True, remove_random=True)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0966f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_cpu(model, device, rep = 10):\n",
    "    model = model.to(device=device)\n",
    "    x = torch.rand((1, 1, 29, 29), device=device)\n",
    "    timings=np.zeros((rep,1))\n",
    "    for i in range(rep):    \n",
    "        start_time = time.time()\n",
    "        out = model(x)\n",
    "        timings[i] = time.time() - start_time\n",
    "    mean_syn = np.sum(timings) / rep\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee739c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_graph_reconstruction_loss(reconstructed, original, batch_index, reduced=\"mean\"):\n",
    "    \"\"\"\n",
    "    Calculate the mean reconstruction loss for each graph in a batch.\n",
    "    \n",
    "    Args:\n",
    "        reconstructed (torch.Tensor): Reconstructed node features, shape [num_nodes, num_features].\n",
    "        original (torch.Tensor): Original node features, shape [num_nodes, num_features].\n",
    "        batch_index (torch.Tensor): Batch indices mapping each node to a graph, shape [num_nodes].\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Mean reconstruction loss for each graph, shape [num_graphs].\n",
    "    \"\"\"\n",
    "    # Calculate MSE loss for each node\n",
    "    node_mse_loss = torch.mean((reconstructed - original) ** 2, dim=1)  # Shape: [num_nodes]\n",
    "\n",
    "    # Aggregate losses for each graph\n",
    "    num_graphs = batch_index.max().item() + 1  # Total number of graphs in the batch\n",
    "    graph_losses = torch.zeros(num_graphs, device=reconstructed.device)  # Initialize graph loss storage\n",
    "\n",
    "    for graph_id in range(num_graphs):\n",
    "        # Mask to select nodes belonging to the current graph\n",
    "        graph_mask = (batch_index == graph_id)\n",
    "        \n",
    "        # Mean MSE loss for the current graph\n",
    "        if (reduced == \"mean\"):\n",
    "            graph_losses[graph_id] = torch.mean(node_mse_loss[graph_mask])\n",
    "        elif (reduced == \"none\"):\n",
    "            return graph_losses\n",
    "        else:\n",
    "            graph_losses[graph_id] = sum(node_mse_loss[graph_mask])\n",
    "    return graph_losses\n",
    "\n",
    "def open_set_inference_optimized(ae_model,\n",
    "                                 batch,\n",
    "                                 thresholds,\n",
    "                                 class_centers=None,\n",
    "                                 device='cuda',\n",
    "                                 num_known_classes=None): # Add num_known_classes\n",
    "    \"\"\"\n",
    "    Optimized forward pass for open-set inference.\n",
    "    \"\"\"\n",
    "    ae_model.eval()\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # --- Model Forward Pass (No changes here, assumed to be optimized within ae_model) ---\n",
    "    with torch.no_grad():\n",
    "        M_sup = ae_model(batch, device, acummulate=True, remove_random=True)\n",
    "        graph_emb_sup = ae_model.graph_embedding(M_sup, batch.batch)\n",
    "        graph_emb_sup = F.normalize(graph_emb_sup, p=2, dim=1) # [B, EmbDim]\n",
    "\n",
    "        # Calculate distances to all class centers\n",
    "        dists = torch.cdist(graph_emb_sup, class_centers, p=2) # [B, C_known]\n",
    "        logits = -dists\n",
    "        probs = F.softmax(logits, dim=1) # [B, C_known]\n",
    "        max_probs, pred_cls_known = probs.max(dim=1) # max_probs and indices for known classes\n",
    "\n",
    "        # Reconstruction\n",
    "        # Adjacency reconstruction loss (graph-level)\n",
    "        adj_rec = ae_model.adj_decode(M_sup, batch.batch, use_sigmoid=False)\n",
    "        adj_ori = to_dense_adj(batch.edge_index,\n",
    "                               batch.batch,\n",
    "                               edge_attr=batch.edge_attr[:, 0].unsqueeze(1) if batch.edge_attr is not None else None).squeeze(3)\n",
    "        # Ensure adj_rec and adj_ori have compatible shapes for mse_loss\n",
    "        # This might require padding or careful handling if graph sizes vary significantly\n",
    "        # and ae_model.adj_decode doesn't produce consistently sized outputs per graph\n",
    "        # For now, assuming they are compatible or loss handles it.\n",
    "        adj_loss = F.mse_loss(adj_rec, adj_ori, reduction='none').sum(dim=(1, 2)) # [B]\n",
    "\n",
    "        # Node reconstruction loss (graph-level)\n",
    "        node_hat = ae_model.node_recon(M_sup)\n",
    "        node_rec_loss = calculate_graph_reconstruction_loss(node_hat, batch.x, batch.batch, reduced=\"sum\") # [B]\n",
    "\n",
    "    # --- Open-Set Logic (Vectorized) ---\n",
    "    num_graphs_in_batch = graph_emb_sup.size(0)\n",
    "    if num_known_classes is None and class_centers is not None:\n",
    "        num_known_classes = class_centers.size(0)\n",
    "    elif num_known_classes is None:\n",
    "        raise ValueError(\"num_known_classes must be provided if class_centers is None or for unknown label assignment\")\n",
    "\n",
    "    # Initialize predictions as the predicted known class\n",
    "    pred_out = pred_cls_known.clone() # [B]\n",
    "\n",
    "    # Rule 1: Distance to predicted class center > its threshold (vectorized)\n",
    "    # Gather the specific distance thresholds for each predicted class\n",
    "    # thresholds['distance'] is expected to be a tensor or list of length C_known\n",
    "    distance_thresholds_for_pred_cls = torch.tensor(thresholds['distance'], device=device)[pred_cls_known] # [B]\n",
    "    distances_to_pred_cls = dists.gather(1, pred_cls_known.unsqueeze(1)).squeeze(1) # [B]\n",
    "    unknown_due_to_distance_to_pred = (distances_to_pred_cls > distance_thresholds_for_pred_cls) # [B]\n",
    "\n",
    "    # Initialize reasons (0: benign, 1: known_attack, >1: unknown due to specific anomaly)\n",
    "    reasons = torch.zeros(num_graphs_in_batch, dtype=torch.long, device=device)\n",
    "    reasons[pred_cls_known > 0] = 1 # Mark known attacks (assuming class 0 is benign)\n",
    "\n",
    "    # SVDD distance for benign class (class 0)\n",
    "    d_svdd_benign = dists[:, 0] # [B]\n",
    "\n",
    "    # Identify samples initially predicted as benign (class 0) OR\n",
    "    # those that already violated their predicted class's distance threshold\n",
    "    # These are candidates for being re-classified as 'unknown' based on anomaly metrics\n",
    "    # or staying benign if they pass all checks.\n",
    "    benign_candidates_mask = (pred_cls_known == 0) | unknown_due_to_distance_to_pred # [B]\n",
    "\n",
    "    # --- Anomaly checks for benign_candidates_mask ---\n",
    "    # These flags are only relevant for samples in benign_candidates_mask\n",
    "    adj_flag_all = (adj_loss > thresholds['adj']) # [B]\n",
    "    node_flag_all = (node_rec_loss > thresholds['node']) # [B]\n",
    "    svdd_flag_all = (d_svdd_benign > thresholds['distance'][0]) # [B], distance to benign center threshold\n",
    "\n",
    "    # Combine flags for reason codes (only for benign candidates)\n",
    "    # We apply the benign_candidates_mask *after* calculating all flags to keep indexing simple\n",
    "    adj_flag_bc = adj_flag_all[benign_candidates_mask]\n",
    "    node_flag_bc = node_flag_all[benign_candidates_mask]\n",
    "    svdd_flag_bc = svdd_flag_all[benign_candidates_mask]\n",
    "\n",
    "    # Calculate reason codes for the benign candidates subset\n",
    "    flag_combo_bc = (adj_flag_bc.long() * 1 +\n",
    "                     node_flag_bc.long() * 2 +\n",
    "                     svdd_flag_bc.long() * 4) # yields 0-7 for benign candidates\n",
    "\n",
    "    # Map combo to final reason codes (2-8 for anomalies, 0 if still benign)\n",
    "    # combo_to_reason_map_tensor should be precomputed and on the correct device\n",
    "    # For example:\n",
    "    # _combo_map = {0:0, 1:2, 2:3, 3:5, 4:4, 5:6, 6:7, 7:8}     0 means stays benign/known attack\n",
    "    # combo_to_reason_map_tensor = torch.tensor([_combo_map[i] for i in range(8)], device=device)\n",
    "    # Optimized: Create this map directly\n",
    "    combo_to_reason_map_tensor = torch.tensor([0, 2, 3, 5, 4, 6, 7, 8], device=device, dtype=torch.long)\n",
    "    reasons_for_benign_candidates = combo_to_reason_map_tensor[flag_combo_bc]\n",
    "\n",
    "    # Update reasons for those initially benign candidates\n",
    "    # If reasons_for_benign_candidates > 0, it means it's an anomaly type\n",
    "    reasons[benign_candidates_mask] = torch.where(\n",
    "        reasons_for_benign_candidates > 0, # If an anomaly reason code was generated\n",
    "        reasons_for_benign_candidates,     # Use that anomaly reason\n",
    "        reasons[benign_candidates_mask]    # Otherwise, keep original reason (0 for benign, 1 for known attack if it was a misclassified known that passed distance)\n",
    "    )\n",
    "\n",
    "    # Samples become 'unknown' if:\n",
    "    # 1. They were benign_candidates AND any of their anomaly flags (adj, node, svdd for benign) were true\n",
    "    # 2. OR they initially violated their predicted class's distance threshold (unknown_due_to_distance_to_pred)\n",
    "    is_unknown_anomaly = (benign_candidates_mask & ( (adj_flag_all | node_flag_all | svdd_flag_all)[benign_candidates_mask] )) \\\n",
    "                       | unknown_due_to_distance_to_pred\n",
    "\n",
    "    pred_out[is_unknown_anomaly] = num_known_classes # Assign 'unknown' label (e.g., C_known if labels are 0 to C_known-1)\n",
    "\n",
    "    # Ensure pred_out for samples that are not unknown, but were initially marked as known attacks (>0),\n",
    "    # and did NOT violate distance_to_pred, retain their known attack label.\n",
    "    # This is implicitly handled as pred_out is initialized with pred_cls_known.\n",
    "    # We only overwrite with 'unknown' or keep benign/known_attack.\n",
    "\n",
    "    return pred_out.cpu().numpy(), reasons.cpu().numpy(), \\\n",
    "           d_svdd_benign.cpu(), adj_loss.cpu(), node_rec_loss.cpu(), \\\n",
    "           graph_emb_sup # graph_emb_sup is already on device, return as is or move to cpu() if needed by caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a8d7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_set_inference(ae_model,\n",
    "                       batch,\n",
    "                       thresholds,\n",
    "                       class_centers=None,\n",
    "                       device='cuda',\n",
    "                       num_classes = 5):\n",
    "    ae_model.eval()\n",
    "\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad(): # Disable gradient calculations for inference\n",
    "        # Supervised embedding calculation\n",
    "        M_sup = ae_model(batch, device, acummulate=True, remove_random=True)\n",
    "        graph_emb_sup = ae_model.graph_embedding(M_sup, batch.batch)\n",
    "        graph_emb_sup = F.normalize(graph_emb_sup, p=2, dim=1)\n",
    "\n",
    "        # Distance to class centers and classification\n",
    "        # For batch_size=1, dists will be [1, C_known]\n",
    "        dists = torch.cdist(graph_emb_sup, class_centers, p=2)\n",
    "        logits = -dists # Negative distance can be used as logits for closest class\n",
    "        probs = F.softmax(logits, dim=1) # Softmax over known classes [1, C_known]\n",
    "        _, pred_cls = probs.max(dim=1) # Predicted class for the single graph [1]\n",
    "\n",
    "        # Reconstruction (recon) calculations\n",
    "        # adj_rec will be [1, N, N]\n",
    "        adj_rec = ae_model.adj_decode(M_sup, batch.batch, use_sigmoid=False)\n",
    "        # node_hat is assumed to be a tensor of node-wise errors for the single graph\n",
    "        node_hat = ae_model.node_recon(M_sup)\n",
    "        # adj_ori will be [1, N, N]\n",
    "        adj_ori = to_dense_adj(batch.edge_index,\n",
    "                               batch.batch,\n",
    "                               edge_attr=batch.edge_attr[:, 0].unsqueeze(1)).squeeze(3)\n",
    "\n",
    "        # Calculate reconstruction losses\n",
    "        # Sum over spatial dimensions for adjacency loss for the single graph [1]\n",
    "        adj_loss = F.mse_loss(adj_rec, adj_ori, reduction='none').sum(dim=(1, 2))\n",
    "        # Sum over all node errors for node reconstruction loss for the single graph [1]\n",
    "        rec_loss = node_hat.sum(dim=-1).unsqueeze(0) # Ensure it's [1] for batch_size=1 consistent with adj_loss\n",
    "\n",
    "    # 1) For each sample, find the closest class center and check against its threshold\n",
    "    pred_out = pred_cls.cpu().numpy()              # 0 = benign, >0 = known attack\n",
    "\n",
    "    unknown_distance = torch.tensor([False]).to(device)\n",
    "    distance = dists[0, pred_out[0]]\n",
    "    if (distance > thresholds['distance'][pred_out[0]]):\n",
    "        unknown_distance[0] = True\n",
    "\n",
    "    return pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854217cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(model, test_loader, device='cuda', num_warmup=10, num_repeats=100, num_classes =5):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        print(f\"Warming up for {num_warmup} iterations...\")\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            open_set_inference(model, \n",
    "                                 batch, \n",
    "                                 thresholds={'distance': [0.5]*num_classes, 'adj': 0.1, 'node': 0.1}, \n",
    "                                 device=device,\n",
    "                                 class_centers=torch.zeros((num_classes, 128), device=device), \n",
    "                                 num_classes=num_classes)\n",
    "            if i >= num_warmup - 1:\n",
    "                break\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"Starting timed inference over {num_repeats} iterations...\")\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= num_repeats:\n",
    "                break\n",
    "            batch = batch.to(device)\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.perf_counter()\n",
    "            open_set_inference(model, \n",
    "                                batch, \n",
    "                                thresholds={'distance': [0.5]*num_classes, 'adj': 0.1, 'node': 0.1}, \n",
    "                                device=device,\n",
    "                                class_centers=torch.zeros((num_classes, 128), device=device), \n",
    "                                num_classes=num_classes)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.perf_counter()\n",
    "            times.append(end_time - start_time)\n",
    "\n",
    "        times = np.array(times)\n",
    "        print(f\"Tested {len(times)} samples.\")\n",
    "        print(f\"Mean Latency: {np.mean(times)*1000:.2f} ms\")\n",
    "        print(f\"Median Latency: {np.median(times)*1000:.2f} ms\")\n",
    "        print(f\"Throughput: {1/np.mean(times):.2f} samples/sec\")\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "            print(f\"Max GPU memory used: {mem:.2f} MB\")\n",
    "            torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72577c8c-1c7f-41ef-a5ca-25518345ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "def load_and_split_graphs(\n",
    "    path: str,\n",
    "    exclude: List[str] = None,\n",
    "    train_ratio: float = 0.8,\n",
    "    seed: int = 2025\n",
    ") -> Tuple[List[Any], List[Any], List[str]]:\n",
    "    \"\"\"\n",
    "    Loads graph data from .pt files in a specified directory, excludes certain graphs,\n",
    "    and splits them into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        path (str): The directory containing the .pt graph files.\n",
    "        exclude (List[str], optional): A list of graph filenames (without .pt extension)\n",
    "                                       to exclude from loading. Defaults to None.\n",
    "        train_ratio (float, optional): The proportion of graphs to allocate to the\n",
    "                                       training set. Should be between 0.0 and 1.0.\n",
    "                                       Defaults to 0.8.\n",
    "        seed (int, optional): The random seed for reproducibility of the split.\n",
    "                              Defaults to 2025.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Any], List[Any], List[str]]: A tuple containing:\n",
    "            - train_graphs (List[Any]): List of graph objects for the training set.\n",
    "            - test_graphs (List[Any]): List of graph objects for the testing set.\n",
    "            - graphs_names (List[str]): List of all loaded graph filenames (base names,\n",
    "                                        without .pt extension and excluding excluded graphs).\n",
    "    \"\"\"\n",
    "    if exclude is None:\n",
    "        exclude = []\n",
    "\n",
    "    all_graphs_with_names = []\n",
    "    loaded_graph_names = []\n",
    "\n",
    "    # Ensure the path exists\n",
    "    if not os.path.isdir(path):\n",
    "        print(f\"Error: Directory not found at '{path}'\")\n",
    "        return [], [], []\n",
    "\n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".pt\"):\n",
    "            graph_name = os.path.splitext(filename)[0] # Get name without .pt extension\n",
    "\n",
    "            if graph_name in exclude:\n",
    "                print(f\"Skipping excluded graph: {filename}\")\n",
    "                continue\n",
    "\n",
    "            filepath = os.path.join(path, filename)\n",
    "            try:\n",
    "                # Load the graph object\n",
    "                graph_data = torch.load(filepath)\n",
    "                all_graphs_with_names.extend(graph_data)\n",
    "                loaded_graph_names.append(graph_name)\n",
    "                print(f\"Loaded graph: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not all_graphs_with_names:\n",
    "        print(\"No graphs loaded or all graphs were excluded.\")\n",
    "        return [], [], []\n",
    "    \n",
    "    print(all_graphs_with_names[0])\n",
    "\n",
    "\n",
    "    # Split into train and test sets\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_graphs_with_names) # Shuffle the combined list for random split\n",
    "\n",
    "    num_train = int(len(all_graphs_with_names) * train_ratio)\n",
    "\n",
    "    train_data = all_graphs_with_names[:num_train]\n",
    "    test_data = all_graphs_with_names[num_train:]\n",
    "\n",
    "    train_graphs = [item for item in train_data]\n",
    "    test_graphs = [item for item in test_data]\n",
    "    \n",
    "    # Return the names of the graphs that were actually loaded and split\n",
    "    # For clarity, we'll return the names of the graphs that ended up in train/test\n",
    "    # and the original list of all loaded names (before split).\n",
    "    \n",
    "    return train_graphs, test_graphs, loaded_graph_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215aaead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: reverse_light_on_graphs.pt\n",
      "Loaded graph: correlated_signal_graphs.pt\n",
      "Loaded graph: reverse_light_off_graphs.pt\n",
      "Loaded graph: max_speedometer_graphs.pt\n",
      "Loaded graph: max_engine_coolant_temp_graphs.pt\n",
      "Data(x=[57, 9], edge_index=[2, 128], edge_attr=[128, 3], y=[1], node_labels=[57])\n"
     ]
    }
   ],
   "source": [
    "path = f'/home/dhkim/OpenSetGNN-main/data'\n",
    "\n",
    "train_graphs, test_graphs, graphs_names = load_and_split_graphs(path, exclude=[], train_ratio=0.8, seed=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1314d766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[69, 9], edge_index=[2, 130], edge_attr=[130, 3], y=[1], node_labels=[69], batch=[69], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "warmup_loader = DataLoader([train_graphs[0]], batch_size=1, shuffle=False)\n",
    "\n",
    "for graph in test_graphs:\n",
    "    graph.edge_attr = graph.edge_attr[:, 0].reshape(-1, 1).clone().detach()\n",
    "\n",
    "test_loader = DataLoader(test_graphs, batch_size=1, shuffle=False)\n",
    "\n",
    "dummy_input = next(iter(warmup_loader)).to('cuda')\n",
    "print(dummy_input)\n",
    "dummy_input.edge_attr = dummy_input.edge_attr[:, 0].reshape(-1, 1).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d219dbbc-0922-4a0c-85af-639bebd46f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4681"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4de7335d-a33b-4f20-9fad-94d3faea6fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(np.unique([g.y.item() for g in train_graphs]))\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a467ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim/pyg_env/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'nn.glob.Set2Set' is deprecated, use 'nn.aggr.Set2Set' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.616414209842682, 0.5407431497686204)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAE_CLS_Link_NODE_Cosine_SupCon_2(num_features=9, embedding_size=32, projection_emb=128, activate='gelu', layer_type='gatv2', num_layers=2, directed=False, id_dim=1, num_classes = NUM_CLASSES, linear_node=True, num_id_embeddings=2048, attn_head=1)\n",
    "measure_time_gpu(dummy_input, model, 'cuda', rep=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e4d174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.029526207923889, 0.3392483823156303)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incep = SupIncepResnet(num_classes=NUM_CLASSES)\n",
    "measure_time_gpu(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(), incep, 'cuda', rep=1000, none_gnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4d65e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.491536445140839, 0.7479123584856062)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supcon = SupCEResNet(name='resnet18', num_classes=NUM_CLASSES)\n",
    "measure_time_gpu(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(), supcon, 'cuda', rep=1000, none_gnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa9169f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up for 10 iterations...\n",
      "Starting timed inference over 100 iterations...\n",
      "Tested 100 samples.\n",
      "Mean Latency: 16.33 ms\n",
      "Median Latency: 15.16 ms\n",
      "Throughput: 61.24 samples/sec\n",
      "Max GPU memory used: 25.60 MB\n"
     ]
    }
   ],
   "source": [
    "analyze_performance(model, test_loader, device='cuda', num_warmup=10, num_repeats=100, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30a05d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gnn_model(model, example_data, device=None, repeat=10):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device).eval()\n",
    "    example_data = example_data.to(device)\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                 record_shapes=True,\n",
    "                 profile_memory=True,\n",
    "                 with_flops=True) as prof:\n",
    "        with torch.no_grad():\n",
    "            for _ in range(repeat):\n",
    "                with record_function(\"model_inference\"):\n",
    "                    model(example_data)\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=15))\n",
    "    print(prof.key_averages().table(sort_by=\"flops\", row_limit=15))\n",
    "    # For total FLOPs (note: double to get MACs for real-valued ops)\n",
    "    total_flops = sum([item.flops for item in prof.key_averages() if hasattr(item, 'flops')])\n",
    "    print(f'Estimated total FLOPs: {clever_format([total_flops], \"%.3f\")}')\n",
    "    print(f'Estimated total MACs: {(total_flops/2)} {clever_format([total_flops/2], \"%.3f\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fba16d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference        22.52%      39.919ms        99.46%     176.265ms      17.627ms      42.338ms        23.98%     175.842ms      17.584ms         -40 b      -4.34 Kb           0 b     -14.95 Mb            10            --  \n",
      "         aten::cudnn_convolution        18.49%      32.761ms        20.74%      36.764ms     183.820us      34.503ms        19.54%      38.156ms     190.780us           0 b           0 b       5.15 Mb     -58.17 Mb           200            --  \n",
      "          aten::cudnn_batch_norm        11.75%      20.815ms        22.31%      39.532ms     197.660us      22.691ms        12.85%      39.545ms     197.725us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                     aten::empty         9.75%      17.280ms         9.75%      17.280ms      14.558us      16.209ms         9.18%      16.209ms      13.655us       3.90 Kb       3.90 Kb      68.44 Mb      68.44 Mb          1187            --  \n",
      "                 aten::clamp_min         7.34%      13.005ms        16.54%      29.319ms      86.232us      12.341ms         6.99%      28.695ms      84.397us           0 b           0 b       9.28 Mb           0 b           340            --  \n",
      "              aten::_convolution         3.95%       6.996ms        24.69%      43.760ms     218.800us       5.786ms         3.28%      43.942ms     219.710us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                aten::batch_norm         3.18%       5.643ms        28.60%      50.692ms     253.460us       5.308ms         3.01%      49.991ms     249.955us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "    aten::_batch_norm_impl_index         3.11%       5.517ms        25.42%      45.049ms     225.245us       5.138ms         2.91%      44.683ms     223.415us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                    aten::conv2d         3.40%       6.027ms        31.21%      55.311ms     276.555us       5.101ms         2.89%      54.027ms     270.135us           0 b           0 b       5.15 Mb           0 b           200    640435.520  \n",
      "               aten::convolution         3.12%       5.524ms        27.81%      49.284ms     246.420us       4.984ms         2.82%      48.926ms     244.630us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                aten::empty_like         2.97%       5.257ms         6.49%      11.494ms      57.470us       4.384ms         2.48%      10.628ms      53.140us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                      aten::relu         2.17%       3.853ms        12.70%      22.500ms     132.353us       4.175ms         2.36%      22.057ms     129.747us           0 b           0 b       4.64 Mb           0 b           170            --  \n",
      "                   aten::resize_         2.34%       4.154ms         2.34%       4.154ms      24.435us       4.113ms         2.33%       4.113ms      24.194us           0 b           0 b       4.64 Mb       4.64 Mb           170            --  \n",
      "                     aten::addmm         1.27%       2.246ms         1.46%       2.586ms     258.600us       2.280ms         1.29%       2.589ms     258.900us           0 b           0 b       5.00 Kb       5.00 Kb            10        15.360  \n",
      "                      aten::add_         1.38%       2.442ms         1.38%       2.442ms      30.525us       2.266ms         1.28%       2.266ms      28.325us           0 b           0 b           0 b           0 b            80            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 177.224ms\n",
      "Self CUDA time total: 176.566ms\n",
      "\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    aten::conv2d         3.40%       6.027ms        31.21%      55.311ms     276.555us       5.101ms         2.89%      54.027ms     270.135us           0 b           0 b       5.15 Mb           0 b           200    640435.520  \n",
      "                     aten::addmm         1.27%       2.246ms         1.46%       2.586ms     258.600us       2.280ms         1.29%       2.589ms     258.900us           0 b           0 b       5.00 Kb       5.00 Kb            10        15.360  \n",
      "                     aten::zeros         0.30%     536.000us         0.54%     959.000us      95.900us     397.000us         0.22%     724.000us      72.400us          40 b           0 b           0 b           0 b            10            --  \n",
      "                     aten::empty         0.07%     121.000us         0.07%     121.000us      40.333us       0.000us         0.00%       0.000us       0.000us         444 b         444 b      42.50 Kb      42.50 Kb             3            --  \n",
      "                     aten::zero_         0.01%      10.000us         0.01%      10.000us      10.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1            --  \n",
      "                 model_inference        22.52%      39.919ms        99.46%     176.265ms      17.627ms      42.338ms        23.98%     175.842ms      17.584ms         -40 b      -4.34 Kb           0 b     -14.95 Mb            10            --  \n",
      "               aten::convolution         3.12%       5.524ms        27.81%      49.284ms     246.420us       4.984ms         2.82%      48.926ms     244.630us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "              aten::_convolution         3.95%       6.996ms        24.69%      43.760ms     218.800us       5.786ms         3.28%      43.942ms     219.710us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "         aten::cudnn_convolution        18.49%      32.761ms        20.74%      36.764ms     183.820us      34.503ms        19.54%      38.156ms     190.780us           0 b           0 b       5.15 Mb     -58.17 Mb           200            --  \n",
      "                     aten::empty         9.75%      17.280ms         9.75%      17.280ms      14.558us      16.209ms         9.18%      16.209ms      13.655us       3.90 Kb       3.90 Kb      68.44 Mb      68.44 Mb          1187            --  \n",
      "                aten::batch_norm         3.18%       5.643ms        28.60%      50.692ms     253.460us       5.308ms         3.01%      49.991ms     249.955us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "    aten::_batch_norm_impl_index         3.11%       5.517ms        25.42%      45.049ms     225.245us       5.138ms         2.91%      44.683ms     223.415us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "          aten::cudnn_batch_norm        11.75%      20.815ms        22.31%      39.532ms     197.660us      22.691ms        12.85%      39.545ms     197.725us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                aten::empty_like         2.97%       5.257ms         6.49%      11.494ms      57.470us       4.384ms         2.48%      10.628ms      53.140us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                      aten::view         1.18%       2.092ms         1.18%       2.092ms      10.460us       1.785ms         1.01%       1.785ms       8.925us           0 b           0 b           0 b           0 b           200            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 177.224ms\n",
      "Self CUDA time total: 176.566ms\n",
      "\n",
      "Estimated total FLOPs: 640.451M\n",
      "Estimated total MACs: 320225440.0 320.225M\n"
     ]
    }
   ],
   "source": [
    "profile_gnn_model(supcon.to(device='cpu'), torch.randn(1, 1, 29, 29, dtype=torch.float).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecb460ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            model_inference        38.15%     126.420ms        99.77%     330.665ms      33.066ms     133.043ms        40.16%     330.656ms      33.066ms     271.14 Kb    -126.84 Kb    -274.00 Kb      -5.57 Mb            10            --  \n",
      "                                aten::copy_         8.14%      26.979ms         8.14%      26.979ms      62.451us      26.769ms         8.08%      26.769ms      61.965us           0 b           0 b           0 b           0 b           432            --  \n",
      "                             aten::_to_copy         5.54%      18.365ms        16.61%      55.045ms     130.438us      16.851ms         5.09%      53.580ms     126.967us     393.68 Kb           0 b     190.00 Kb           0 b           422            --  \n",
      "                        aten::empty_strided         3.25%      10.764ms         3.25%      10.764ms      24.298us      11.245ms         3.39%      11.245ms      25.384us     393.68 Kb     393.68 Kb     295.50 Kb     295.50 Kb           443            --  \n",
      "                                   aten::to         3.62%      11.992ms        20.23%      67.037ms     104.745us      10.968ms         3.31%      64.548ms     100.856us     393.68 Kb           0 b     190.00 Kb           0 b           640            --  \n",
      "                         aten::scatter_add_         2.37%       7.871ms         3.03%      10.052ms      83.767us       7.741ms         2.34%       9.701ms      80.842us           0 b           0 b           0 b           0 b           120            --  \n",
      "                         aten::index_select         2.09%       6.927ms         3.41%      11.290ms      94.083us       7.552ms         2.28%      11.107ms      92.558us           0 b           0 b       1.04 Mb           0 b           120            --  \n",
      "    aten::_has_compatible_shallow_copy_type         2.87%       9.501ms         2.87%       9.501ms       8.169us       7.323ms         2.21%       7.323ms       6.297us           0 b           0 b           0 b           0 b          1163            --  \n",
      "                                aten::empty         2.26%       7.493ms         2.26%       7.493ms      19.462us       7.207ms         2.18%       7.207ms      18.719us       4.33 Kb       4.33 Kb     298.50 Kb     298.50 Kb           385            --  \n",
      "                           aten::as_strided         2.33%       7.724ms         2.33%       7.724ms       9.108us       6.972ms         2.10%       6.972ms       8.222us           0 b           0 b           0 b           0 b           848            --  \n",
      "                               aten::expand         1.84%       6.103ms         2.42%       8.028ms      36.491us       6.018ms         1.82%       7.726ms      35.118us           0 b           0 b           0 b           0 b           220            --  \n",
      "                            aten::unsqueeze         1.70%       5.624ms         2.28%       7.547ms      37.735us       5.285ms         1.60%       7.006ms      35.030us           0 b           0 b           0 b           0 b           200            --  \n",
      "                                aten::fill_         1.27%       4.220ms         1.27%       4.220ms      19.182us       5.172ms         1.56%       5.172ms      23.509us           0 b           0 b           0 b           0 b           220            --  \n",
      "                                aten::zeros         1.48%       4.903ms         3.95%      13.088ms     100.677us       4.934ms         1.49%      13.697ms     105.362us          40 b           0 b     230.00 Kb           0 b           130            --  \n",
      "                                aten::addmm         1.45%       4.803ms         1.87%       6.194ms     154.850us       4.736ms         1.43%       6.275ms     156.875us           0 b           0 b     360.00 Kb     360.00 Kb            40      3621.120  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 331.412ms\n",
      "Self CUDA time total: 331.248ms\n",
      "\n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                aten::addmm         1.45%       4.803ms         1.87%       6.194ms     154.850us       4.736ms         1.43%       6.275ms     156.875us           0 b           0 b     360.00 Kb     360.00 Kb            40      3621.120  \n",
      "                                  aten::mul         1.44%       4.787ms         1.44%       4.787ms      47.870us       4.553ms         1.37%       4.553ms      45.530us           0 b           0 b       1.17 Mb       1.17 Mb           100       255.360  \n",
      "                                   aten::mm         0.44%       1.442ms         0.44%       1.442ms      72.100us       1.385ms         0.42%       1.385ms      69.250us           0 b           0 b     330.00 Kb     330.00 Kb            20       166.400  \n",
      "                                  aten::add         1.08%       3.583ms         1.08%       3.583ms      44.788us       3.489ms         1.05%       3.489ms      43.612us           0 b           0 b     540.00 Kb     540.00 Kb            80       130.600  \n",
      "                                aten::zeros         1.48%       4.903ms         3.95%      13.088ms     100.677us       4.934ms         1.49%      13.697ms     105.362us          40 b           0 b     230.00 Kb           0 b           130            --  \n",
      "                                aten::empty         0.05%     158.000us         0.05%     158.000us      31.600us       0.000us         0.00%       0.000us       0.000us           4 b           4 b       1.50 Kb       1.50 Kb             5            --  \n",
      "                                aten::zero_         0.97%       3.222ms         1.76%       5.840ms      38.933us       2.961ms         0.89%       6.588ms      43.920us           0 b           0 b           0 b           0 b           150            --  \n",
      "                            model_inference        38.15%     126.420ms        99.77%     330.665ms      33.066ms     133.043ms        40.16%     330.656ms      33.066ms     271.14 Kb    -126.84 Kb    -274.00 Kb      -5.57 Mb            10            --  \n",
      "                                aten::empty         2.26%       7.493ms         2.26%       7.493ms      19.462us       7.207ms         2.18%       7.207ms      18.719us       4.33 Kb       4.33 Kb     298.50 Kb     298.50 Kb           385            --  \n",
      "                                   aten::to         3.62%      11.992ms        20.23%      67.037ms     104.745us      10.968ms         3.31%      64.548ms     100.856us     393.68 Kb           0 b     190.00 Kb           0 b           640            --  \n",
      "                             aten::_to_copy         5.54%      18.365ms        16.61%      55.045ms     130.438us      16.851ms         5.09%      53.580ms     126.967us     393.68 Kb           0 b     190.00 Kb           0 b           422            --  \n",
      "                        aten::empty_strided         3.25%      10.764ms         3.25%      10.764ms      24.298us      11.245ms         3.39%      11.245ms      25.384us     393.68 Kb     393.68 Kb     295.50 Kb     295.50 Kb           443            --  \n",
      "                                aten::copy_         8.14%      26.979ms         8.14%      26.979ms      62.451us      26.769ms         8.08%      26.769ms      61.965us           0 b           0 b           0 b           0 b           432            --  \n",
      "    aten::_has_compatible_shallow_copy_type         2.87%       9.501ms         2.87%       9.501ms       8.169us       7.323ms         2.21%       7.323ms       6.297us           0 b           0 b           0 b           0 b          1163            --  \n",
      "    aten::_has_compatible_shallow_copy_type         0.05%     175.000us         0.05%     175.000us      10.294us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            17            --  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 331.412ms\n",
      "Self CUDA time total: 331.248ms\n",
      "\n",
      "Estimated total FLOPs: 4.173M\n",
      "Estimated total MACs: 2086740.0 2.087M\n"
     ]
    }
   ],
   "source": [
    "dummy_input = dummy_input.to(device='cpu')\n",
    "model = model.to(device='cpu')\n",
    "profile_gnn_model(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47bd1543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 97.191M\n",
      "Params: 1.695M\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(incep, inputs=(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(),), verbose=False)\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bcf8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 32.561M\n",
      "Params: 700.662K\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(supcon, inputs=(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(),), verbose=False)\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48100a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 0.0\n",
      "Params: 0.0\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(model, inputs=(dummy_input,), verbose=False)\n",
    "\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393dc5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyg_env)",
   "language": "python",
   "name": "pyg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
