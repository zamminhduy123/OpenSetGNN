{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d403db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('/home/dhkim/OpenSetGNN-main/src/model')))\n",
    "sys.path.append(os.path.join(os.path.dirname('/home/dhkim/OpenSetGNN-main/src/utils')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3f36db-a262-4e8c-a003-6f512e4898f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim/pyg_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.12.0a0+2c916ef.nv22.3\n",
      "PyTorch CUDA Version: 11.4\n",
      "CUDA available: True\n",
      "TorchVision Version: 0.13.0a0+da3794e\n",
      "PyTorch Geometric Version: 2.1.0\n",
      "Torch-scatter Version: 2.1.1\n",
      "Torch-sparse Version: 0.6.15\n",
      "Torch-cluster Version: 1.6.1\n",
      "Tensor on CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import torch_cluster\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"PyTorch CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"TorchVision Version: {torchvision.__version__}\")\n",
    "print(f\"PyTorch Geometric Version: {torch_geometric.__version__}\")\n",
    "print(f\"Torch-scatter Version: {torch_scatter.__version__}\")\n",
    "print(f\"Torch-sparse Version: {torch_sparse.__version__}\")\n",
    "print(f\"Torch-cluster Version: {torch_cluster.__version__}\")\n",
    "\n",
    "# Simple CUDA test\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.randn(5, 5).cuda()\n",
    "    print(f\"Tensor on CUDA: {x.is_cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016f6f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.GAE_Projection_Att import GAE_CLS_Link_NODE_Cosine_SupCon_2\n",
    "from model.resnet_big import SupCEResNet, SupConResNet, LinearClassifier, SupIncepResnet\n",
    "import torch\n",
    "# from torch_geometric.nn import summary\n",
    "from thop import profile\n",
    "import numpy as np\n",
    "import time\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.nn.functional as F\n",
    "from thop import profile as thopprofile, clever_format\n",
    "from torch_geometric.utils import to_dense_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a6e8a-f0f7-488d-9645-5149969635d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519af486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a2b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_gpu(dummy_input, model, device, rep, none_gnn=False):\n",
    "    model = model.to(device=device)\n",
    "    # dummy_input = torch.randn(1, 1, 29, 29, dtype=torch.float).to(device)\n",
    "    # INIT LOGGERS\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = rep\n",
    "    timings=np.zeros((repetitions,1))\n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(100):\n",
    "        if (none_gnn):\n",
    "            _ = model(dummy_input)\n",
    "        else:\n",
    "            _ = model(dummy_input, device, acummulate = True, remove_random=True)\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for rep in range(repetitions):\n",
    "            starter.record()\n",
    "            if (none_gnn):\n",
    "                _ = model(dummy_input)\n",
    "            else:\n",
    "                _ = model(dummy_input, device, acummulate = True, remove_random=True)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0966f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_cpu(model, device, rep = 10):\n",
    "    model = model.to(device=device)\n",
    "    x = torch.rand((1, 1, 29, 29), device=device)\n",
    "    timings=np.zeros((rep,1))\n",
    "    for i in range(rep):    \n",
    "        start_time = time.time()\n",
    "        out = model(x)\n",
    "        timings[i] = time.time() - start_time\n",
    "    mean_syn = np.sum(timings) / rep\n",
    "    std_syn = np.std(timings)\n",
    "    return mean_syn, std_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee739c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_graph_reconstruction_loss(reconstructed, original, batch_index, reduced=\"mean\"):\n",
    "    \"\"\"\n",
    "    Calculate the mean reconstruction loss for each graph in a batch.\n",
    "    \n",
    "    Args:\n",
    "        reconstructed (torch.Tensor): Reconstructed node features, shape [num_nodes, num_features].\n",
    "        original (torch.Tensor): Original node features, shape [num_nodes, num_features].\n",
    "        batch_index (torch.Tensor): Batch indices mapping each node to a graph, shape [num_nodes].\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Mean reconstruction loss for each graph, shape [num_graphs].\n",
    "    \"\"\"\n",
    "    # Calculate MSE loss for each node\n",
    "    node_mse_loss = torch.mean((reconstructed - original) ** 2, dim=1)  # Shape: [num_nodes]\n",
    "\n",
    "    # Aggregate losses for each graph\n",
    "    num_graphs = batch_index.max().item() + 1  # Total number of graphs in the batch\n",
    "    graph_losses = torch.zeros(num_graphs, device=reconstructed.device)  # Initialize graph loss storage\n",
    "\n",
    "    for graph_id in range(num_graphs):\n",
    "        # Mask to select nodes belonging to the current graph\n",
    "        graph_mask = (batch_index == graph_id)\n",
    "        \n",
    "        # Mean MSE loss for the current graph\n",
    "        if (reduced == \"mean\"):\n",
    "            graph_losses[graph_id] = torch.mean(node_mse_loss[graph_mask])\n",
    "        elif (reduced == \"none\"):\n",
    "            return graph_losses\n",
    "        else:\n",
    "            graph_losses[graph_id] = sum(node_mse_loss[graph_mask])\n",
    "    return graph_losses\n",
    "\n",
    "def open_set_inference_optimized(ae_model,\n",
    "                                 batch,\n",
    "                                 thresholds,\n",
    "                                 class_centers=None,\n",
    "                                 device='cuda',\n",
    "                                 num_known_classes=None): # Add num_known_classes\n",
    "    \"\"\"\n",
    "    Optimized forward pass for open-set inference.\n",
    "    \"\"\"\n",
    "    ae_model.eval()\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # --- Model Forward Pass (No changes here, assumed to be optimized within ae_model) ---\n",
    "    with torch.no_grad():\n",
    "        M_sup = ae_model(batch, device, acummulate=True, remove_random=True)\n",
    "        graph_emb_sup = ae_model.graph_embedding(M_sup, batch.batch)\n",
    "        graph_emb_sup = F.normalize(graph_emb_sup, p=2, dim=1) # [B, EmbDim]\n",
    "\n",
    "        # Calculate distances to all class centers\n",
    "        dists = torch.cdist(graph_emb_sup, class_centers, p=2) # [B, C_known]\n",
    "        logits = -dists\n",
    "        probs = F.softmax(logits, dim=1) # [B, C_known]\n",
    "        max_probs, pred_cls_known = probs.max(dim=1) # max_probs and indices for known classes\n",
    "\n",
    "        # Reconstruction\n",
    "        # Adjacency reconstruction loss (graph-level)\n",
    "        adj_rec = ae_model.adj_decode(M_sup, batch.batch, use_sigmoid=False)\n",
    "        adj_ori = to_dense_adj(batch.edge_index,\n",
    "                               batch.batch,\n",
    "                               edge_attr=batch.edge_attr[:, 0].unsqueeze(1) if batch.edge_attr is not None else None).squeeze(3)\n",
    "        # Ensure adj_rec and adj_ori have compatible shapes for mse_loss\n",
    "        # This might require padding or careful handling if graph sizes vary significantly\n",
    "        # and ae_model.adj_decode doesn't produce consistently sized outputs per graph\n",
    "        # For now, assuming they are compatible or loss handles it.\n",
    "        adj_loss = F.mse_loss(adj_rec, adj_ori, reduction='none').sum(dim=(1, 2)) # [B]\n",
    "\n",
    "        # Node reconstruction loss (graph-level)\n",
    "        node_hat = ae_model.node_recon(M_sup)\n",
    "        node_rec_loss = calculate_graph_reconstruction_loss(node_hat, batch.x, batch.batch, reduced=\"sum\") # [B]\n",
    "\n",
    "    # --- Open-Set Logic (Vectorized) ---\n",
    "    num_graphs_in_batch = graph_emb_sup.size(0)\n",
    "    if num_known_classes is None and class_centers is not None:\n",
    "        num_known_classes = class_centers.size(0)\n",
    "    elif num_known_classes is None:\n",
    "        raise ValueError(\"num_known_classes must be provided if class_centers is None or for unknown label assignment\")\n",
    "\n",
    "    # Initialize predictions as the predicted known class\n",
    "    pred_out = pred_cls_known.clone() # [B]\n",
    "\n",
    "    # Rule 1: Distance to predicted class center > its threshold (vectorized)\n",
    "    # Gather the specific distance thresholds for each predicted class\n",
    "    # thresholds['distance'] is expected to be a tensor or list of length C_known\n",
    "    distance_thresholds_for_pred_cls = torch.tensor(thresholds['distance'], device=device)[pred_cls_known] # [B]\n",
    "    distances_to_pred_cls = dists.gather(1, pred_cls_known.unsqueeze(1)).squeeze(1) # [B]\n",
    "    unknown_due_to_distance_to_pred = (distances_to_pred_cls > distance_thresholds_for_pred_cls) # [B]\n",
    "\n",
    "    # Initialize reasons (0: benign, 1: known_attack, >1: unknown due to specific anomaly)\n",
    "    reasons = torch.zeros(num_graphs_in_batch, dtype=torch.long, device=device)\n",
    "    reasons[pred_cls_known > 0] = 1 # Mark known attacks (assuming class 0 is benign)\n",
    "\n",
    "    # SVDD distance for benign class (class 0)\n",
    "    d_svdd_benign = dists[:, 0] # [B]\n",
    "\n",
    "    # Identify samples initially predicted as benign (class 0) OR\n",
    "    # those that already violated their predicted class's distance threshold\n",
    "    # These are candidates for being re-classified as 'unknown' based on anomaly metrics\n",
    "    # or staying benign if they pass all checks.\n",
    "    benign_candidates_mask = (pred_cls_known == 0) | unknown_due_to_distance_to_pred # [B]\n",
    "\n",
    "    # --- Anomaly checks for benign_candidates_mask ---\n",
    "    # These flags are only relevant for samples in benign_candidates_mask\n",
    "    adj_flag_all = (adj_loss > thresholds['adj']) # [B]\n",
    "    node_flag_all = (node_rec_loss > thresholds['node']) # [B]\n",
    "    svdd_flag_all = (d_svdd_benign > thresholds['distance'][0]) # [B], distance to benign center threshold\n",
    "\n",
    "    # Combine flags for reason codes (only for benign candidates)\n",
    "    # We apply the benign_candidates_mask *after* calculating all flags to keep indexing simple\n",
    "    adj_flag_bc = adj_flag_all[benign_candidates_mask]\n",
    "    node_flag_bc = node_flag_all[benign_candidates_mask]\n",
    "    svdd_flag_bc = svdd_flag_all[benign_candidates_mask]\n",
    "\n",
    "    # Calculate reason codes for the benign candidates subset\n",
    "    flag_combo_bc = (adj_flag_bc.long() * 1 +\n",
    "                     node_flag_bc.long() * 2 +\n",
    "                     svdd_flag_bc.long() * 4) # yields 0-7 for benign candidates\n",
    "\n",
    "    # Map combo to final reason codes (2-8 for anomalies, 0 if still benign)\n",
    "    # combo_to_reason_map_tensor should be precomputed and on the correct device\n",
    "    # For example:\n",
    "    # _combo_map = {0:0, 1:2, 2:3, 3:5, 4:4, 5:6, 6:7, 7:8}     0 means stays benign/known attack\n",
    "    # combo_to_reason_map_tensor = torch.tensor([_combo_map[i] for i in range(8)], device=device)\n",
    "    # Optimized: Create this map directly\n",
    "    combo_to_reason_map_tensor = torch.tensor([0, 2, 3, 5, 4, 6, 7, 8], device=device, dtype=torch.long)\n",
    "    reasons_for_benign_candidates = combo_to_reason_map_tensor[flag_combo_bc]\n",
    "\n",
    "    # Update reasons for those initially benign candidates\n",
    "    # If reasons_for_benign_candidates > 0, it means it's an anomaly type\n",
    "    reasons[benign_candidates_mask] = torch.where(\n",
    "        reasons_for_benign_candidates > 0, # If an anomaly reason code was generated\n",
    "        reasons_for_benign_candidates,     # Use that anomaly reason\n",
    "        reasons[benign_candidates_mask]    # Otherwise, keep original reason (0 for benign, 1 for known attack if it was a misclassified known that passed distance)\n",
    "    )\n",
    "\n",
    "    # Samples become 'unknown' if:\n",
    "    # 1. They were benign_candidates AND any of their anomaly flags (adj, node, svdd for benign) were true\n",
    "    # 2. OR they initially violated their predicted class's distance threshold (unknown_due_to_distance_to_pred)\n",
    "    is_unknown_anomaly = (benign_candidates_mask & ( (adj_flag_all | node_flag_all | svdd_flag_all)[benign_candidates_mask] )) \\\n",
    "                       | unknown_due_to_distance_to_pred\n",
    "\n",
    "    pred_out[is_unknown_anomaly] = num_known_classes # Assign 'unknown' label (e.g., C_known if labels are 0 to C_known-1)\n",
    "\n",
    "    # Ensure pred_out for samples that are not unknown, but were initially marked as known attacks (>0),\n",
    "    # and did NOT violate distance_to_pred, retain their known attack label.\n",
    "    # This is implicitly handled as pred_out is initialized with pred_cls_known.\n",
    "    # We only overwrite with 'unknown' or keep benign/known_attack.\n",
    "\n",
    "    return pred_out.cpu().numpy(), reasons.cpu().numpy(), \\\n",
    "           d_svdd_benign.cpu(), adj_loss.cpu(), node_rec_loss.cpu(), \\\n",
    "           graph_emb_sup # graph_emb_sup is already on device, return as is or move to cpu() if needed by caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "218ea820-6516-4e82-9348-eeb722cb819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_set_inference_phase_0(ae_model,\n",
    "                       batch,\n",
    "                       thresholds,\n",
    "                       class_centers=None,\n",
    "                       device='cuda',\n",
    "                       num_classes = 5):\n",
    "    M_sup = ae_model(batch, device, acummulate=True, remove_random=True)\n",
    "#     graph_emb_sup = ae_model.graph_embedding(M_sup, batch.batch)\n",
    "#     graph_emb_sup = F.normalize(graph_emb_sup, p=2, dim=1)\n",
    "\n",
    "# #         # Distance to class centers and classification\n",
    "# #         # For batch_size=1, dists will be [1, C_known]\n",
    "#     dists = torch.cdist(graph_emb_sup, class_centers, p=2)\n",
    "#     logits = -dists # Negative distance can be used as logits for closest class\n",
    "#     probs = F.softmax(logits, dim=1) # Softmax over known classes [1, C_known]\n",
    "#     _, pred_cls = probs.max(dim=1) # Predicted class for the single graph [1]\n",
    "\n",
    "#         # Reconstruction (recon) calculations\n",
    "#         # adj_rec will be [1, N, N]\n",
    "#     adj_rec = ae_model.adj_decode_optimized(M_sup, batch.batch, use_sigmoid=False)\n",
    "# #         # node_hat is assumed to be a tensor of node-wise errors for the single graph\n",
    "#     node_hat = ae_model.node_recon(M_sup)\n",
    "# #         # adj_ori will be [1, N, N]\n",
    "#     adj_ori = to_dense_adj(batch.edge_index,\n",
    "#                                batch.batch,\n",
    "#                                edge_attr=batch.edge_attr[:, 0].unsqueeze(1)).squeeze(3)\n",
    "\n",
    "#         # Calculate reconstruction losses\n",
    "#         # Sum over spatial dimensions for adjacency loss for the single graph [1]\n",
    "#         adj_loss = F.mse_loss(adj_rec, adj_ori, reduction='none').sum(dim=(1, 2))\n",
    "#         # Sum over all node errors for node reconstruction loss for the single graph [1]\n",
    "#         rec_loss = node_hat.sum(dim=-1).unsqueeze(0) # Ensure it's [1] for batch_size=1 consistent with adj_loss\n",
    "\n",
    "#     # 1) For each sample, find the closest class center and check against its threshold\n",
    "#     pred_out = pred_cls.cpu().numpy()              # 0 = benign, >0 = known attack\n",
    "\n",
    "#     unknown_distance = torch.tensor([False]).to(device)\n",
    "#     distance = dists[0, pred_out[0]]\n",
    "#     if (distance > thresholds['distance'][pred_out[0]]):\n",
    "#         unknown_distance[0] = True\n",
    "\n",
    "    return M_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1a8d7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_set_inference_phase_1(ae_model,\n",
    "                       batch,\n",
    "                       thresholds,\n",
    "                       class_centers=None,\n",
    "                       device='cuda',\n",
    "                       num_classes = 5):\n",
    "    M_sup = ae_model(batch, device, acummulate=True, remove_random=True)\n",
    "    graph_emb_sup = ae_model.graph_embedding(M_sup, batch.batch)\n",
    "    graph_emb_sup = F.normalize(graph_emb_sup, p=2, dim=1)\n",
    "\n",
    "#         # Distance to class centers and classification\n",
    "#         # For batch_size=1, dists will be [1, C_known]\n",
    "    dists = torch.cdist(graph_emb_sup, class_centers, p=2)\n",
    "    logits = -dists # Negative distance can be used as logits for closest class\n",
    "    probs = F.softmax(logits, dim=1) # Softmax over known classes [1, C_known]\n",
    "    _, pred_cls = probs.max(dim=1) # Predicted class for the single graph [1]\n",
    "\n",
    "#         # Reconstruction (recon) calculations\n",
    "#         # adj_rec will be [1, N, N]\n",
    "#     adj_rec = ae_model.adj_decode_optimized(M_sup, batch.batch, use_sigmoid=False)\n",
    "# #         # node_hat is assumed to be a tensor of node-wise errors for the single graph\n",
    "#     node_hat = ae_model.node_recon(M_sup)\n",
    "# #         # adj_ori will be [1, N, N]\n",
    "#     adj_ori = to_dense_adj(batch.edge_index,\n",
    "#                                batch.batch,\n",
    "#                                edge_attr=batch.edge_attr[:, 0].unsqueeze(1)).squeeze(3)\n",
    "\n",
    "#         # Calculate reconstruction losses\n",
    "#         # Sum over spatial dimensions for adjacency loss for the single graph [1]\n",
    "#         adj_loss = F.mse_loss(adj_rec, adj_ori, reduction='none').sum(dim=(1, 2))\n",
    "#         # Sum over all node errors for node reconstruction loss for the single graph [1]\n",
    "#         rec_loss = node_hat.sum(dim=-1).unsqueeze(0) # Ensure it's [1] for batch_size=1 consistent with adj_loss\n",
    "\n",
    "#     # 1) For each sample, find the closest class center and check against its threshold\n",
    "    pred_out = pred_cls.cpu().numpy()              # 0 = benign, >0 = known attack\n",
    "\n",
    "    unknown_distance = torch.tensor([False]).to(device)\n",
    "    distance = dists[0, pred_out[0]]\n",
    "    if (distance > thresholds['distance'][pred_out[0]]):\n",
    "        unknown_distance[0] = True\n",
    "\n",
    "    return M_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50065847-19ea-4f40-9942-9527f8657204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_set_inference_phase_2(ae_model,\n",
    "                       batch,\n",
    "                       thresholds,\n",
    "                       class_centers=None,\n",
    "                       device='cuda',\n",
    "                       num_classes = 5):\n",
    "    M_sup = ae_model(batch, device, acummulate=True, remove_random=True)\n",
    "#     graph_emb_sup = ae_model.graph_embedding(M_sup, batch.batch)\n",
    "#     graph_emb_sup = F.normalize(graph_emb_sup, p=2, dim=1)\n",
    "\n",
    "# #         # Distance to class centers and classification\n",
    "# #         # For batch_size=1, dists will be [1, C_known]\n",
    "#     dists = torch.cdist(graph_emb_sup, class_centers, p=2)\n",
    "#     logits = -dists # Negative distance can be used as logits for closest class\n",
    "#     probs = F.softmax(logits, dim=1) # Softmax over known classes [1, C_known]\n",
    "#     _, pred_cls = probs.max(dim=1) # Predicted class for the single graph [1]\n",
    "\n",
    "        # Reconstruction (recon) calculations\n",
    "        # adj_rec will be [1, N, N]\n",
    "    adj_rec = ae_model.adj_decode_optimized(M_sup, batch.batch, use_sigmoid=False)\n",
    "#         # node_hat is assumed to be a tensor of node-wise errors for the single graph\n",
    "    node_hat = ae_model.node_recon(M_sup)\n",
    "#         # adj_ori will be [1, N, N]\n",
    "    adj_ori = to_dense_adj(batch.edge_index,\n",
    "                               batch.batch,\n",
    "                               edge_attr=batch.edge_attr[:, 0].unsqueeze(1)).squeeze(3)\n",
    "\n",
    "    # Calculate reconstruction losses\n",
    "    # Sum over spatial dimensions for adjacency loss for the single graph [1]\n",
    "    adj_loss = F.mse_loss(adj_rec, adj_ori, reduction='none').sum(dim=(1, 2))\n",
    "    # Sum over all node errors for node reconstruction loss for the single graph [1]\n",
    "    rec_loss = node_hat.sum(dim=-1).unsqueeze(0) # Ensure it's [1] for batch_size=1 consistent with adj_loss\n",
    "\n",
    "    # 1) For each sample, find the closest class center and check against its threshold\n",
    "    # pred_out = pred_cls.cpu().numpy()              # 0 = benign, >0 = known attack\n",
    "\n",
    "    # unknown_distance = torch.tensor([False]).to(device)\n",
    "    # distance = dists[0, pred_out[0]]\n",
    "    # if (distance > thresholds['distance'][pred_out[0]]):\n",
    "    #     unknown_distance[0] = True\n",
    "\n",
    "    return M_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "854217cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def analyze_performance_time_counter(model, test_loader, device='cuda', num_warmup=10, num_repeats=100, num_classes=5):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    times, times_1, times_2 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Warm-up\n",
    "        print(f\"Warming up for {num_warmup} iterations...\")\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= num_warmup:\n",
    "                break\n",
    "            batch = batch.to(device)\n",
    "            _ = model(batch) # Assuming model call is the main operation\n",
    "\n",
    "        print(f\"Starting timed inference over {num_repeats} iterations...\")\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= num_repeats:\n",
    "                break\n",
    "\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            # Ensure GPU is idle before starting the timer\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            open_set_inference_phase_0(model, \n",
    "                                 batch, \n",
    "                                 thresholds={'distance': [0.5]*num_classes, 'adj': 0.1, 'node': 0.1}, \n",
    "                                 device=device,\n",
    "                                 class_centers=torch.zeros((num_classes, 128), device=device), \n",
    "                                 num_classes=num_classes)\n",
    "            \n",
    "            # Wait for the operation to complete\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            end_time = time.perf_counter()\n",
    "            \n",
    "            # Time is in seconds, convert to milliseconds\n",
    "            times.append((end_time - start_time) * 1000)\n",
    "            \n",
    "            # Ensure GPU is idle before starting the timer\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            open_set_inference_phase_1(model, \n",
    "                                 batch, \n",
    "                                 thresholds={'distance': [0.5]*num_classes, 'adj': 0.1, 'node': 0.1}, \n",
    "                                 device=device,\n",
    "                                 class_centers=torch.zeros((num_classes, 128), device=device), \n",
    "                                 num_classes=num_classes)\n",
    "            \n",
    "            # Wait for the operation to complete\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            end_time = time.perf_counter()\n",
    "            \n",
    "            # Time is in seconds, convert to milliseconds\n",
    "            times_1.append((end_time - start_time) * 1000)\n",
    "            \n",
    "            # Ensure GPU is idle before starting the timer\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            open_set_inference_phase_2(model, \n",
    "                                 batch, \n",
    "                                 thresholds={'distance': [0.5]*num_classes, 'adj': 0.1, 'node': 0.1}, \n",
    "                                 device=device,\n",
    "                                 class_centers=torch.zeros((num_classes, 128), device=device), \n",
    "                                 num_classes=num_classes)\n",
    "            \n",
    "            # Wait for the operation to complete\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            end_time = time.perf_counter()\n",
    "            \n",
    "            # Time is in seconds, convert to milliseconds\n",
    "            times_2.append((end_time - start_time) * 1000)\n",
    "\n",
    "        times = np.array(times)\n",
    "        times_1 = np.array(times_1)\n",
    "        times_2 = np.array(times_2)\n",
    "        \n",
    "        mean_enc = np.mean(times)\n",
    "        med_enc = np.median(times)\n",
    "        throughput_enc = 1000 / np.mean(times)\n",
    "        print(f\"Tested {len(times)} samples.\")\n",
    "        print(f\"Mean Latency Encoding: {np.mean(times):.2f} ms\")\n",
    "        print(f\"Median Latency Encoding: {np.median(times):.2f} ms\")\n",
    "        print(f\"Throughput Encoding: {1000 / np.mean(times):.2f} samples/sec\")\n",
    "        \n",
    "        print(f\"Mean Latency Classification: {(np.mean(times_1) - mean_enc):.2f} ms\")\n",
    "        print(f\"Median Latency Classification: {(np.median(times_1) - med_enc):.2f} ms\")\n",
    "        print(f\"Throughput Classification: {1000 / (np.mean(times_1)):.2f} samples/sec\")\n",
    "        \n",
    "        print(f\"Mean Latency Anomaly Detection: {(np.mean(times_2) - mean_enc):.2f} ms\")\n",
    "        print(f\"Median Latency Anomaly Detection: {(np.median(times_2) - med_enc):.2f} ms\")\n",
    "        print(f\"Throughput Anomaly Detection: {1000 / (np.mean(times_2)):.2f} samples/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72577c8c-1c7f-41ef-a5ca-25518345ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "def load_and_split_graphs(\n",
    "    path: str,\n",
    "    exclude: List[str] = None,\n",
    "    train_ratio: float = 0.8,\n",
    "    seed: int = 2025\n",
    ") -> Tuple[List[Any], List[Any], List[str]]:\n",
    "    \"\"\"\n",
    "    Loads graph data from .pt files in a specified directory, excludes certain graphs,\n",
    "    and splits them into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        path (str): The directory containing the .pt graph files.\n",
    "        exclude (List[str], optional): A list of graph filenames (without .pt extension)\n",
    "                                       to exclude from loading. Defaults to None.\n",
    "        train_ratio (float, optional): The proportion of graphs to allocate to the\n",
    "                                       training set. Should be between 0.0 and 1.0.\n",
    "                                       Defaults to 0.8.\n",
    "        seed (int, optional): The random seed for reproducibility of the split.\n",
    "                              Defaults to 2025.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Any], List[Any], List[str]]: A tuple containing:\n",
    "            - train_graphs (List[Any]): List of graph objects for the training set.\n",
    "            - test_graphs (List[Any]): List of graph objects for the testing set.\n",
    "            - graphs_names (List[str]): List of all loaded graph filenames (base names,\n",
    "                                        without .pt extension and excluding excluded graphs).\n",
    "    \"\"\"\n",
    "    if exclude is None:\n",
    "        exclude = []\n",
    "\n",
    "    all_graphs_with_names = []\n",
    "    loaded_graph_names = []\n",
    "\n",
    "    # Ensure the path exists\n",
    "    if not os.path.isdir(path):\n",
    "        print(f\"Error: Directory not found at '{path}'\")\n",
    "        return [], [], []\n",
    "\n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".pt\"):\n",
    "            graph_name = os.path.splitext(filename)[0] # Get name without .pt extension\n",
    "\n",
    "            if graph_name in exclude:\n",
    "                print(f\"Skipping excluded graph: {filename}\")\n",
    "                continue\n",
    "\n",
    "            filepath = os.path.join(path, filename)\n",
    "            try:\n",
    "                # Load the graph object\n",
    "                graph_data = torch.load(filepath)\n",
    "                all_graphs_with_names.extend(graph_data)\n",
    "                loaded_graph_names.append(graph_name)\n",
    "                print(f\"Loaded graph: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not all_graphs_with_names:\n",
    "        print(\"No graphs loaded or all graphs were excluded.\")\n",
    "        return [], [], []\n",
    "    \n",
    "    print(all_graphs_with_names[0])\n",
    "\n",
    "\n",
    "    # Split into train and test sets\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_graphs_with_names) # Shuffle the combined list for random split\n",
    "\n",
    "    num_train = int(len(all_graphs_with_names) * train_ratio)\n",
    "\n",
    "    train_data = all_graphs_with_names[:num_train]\n",
    "    test_data = all_graphs_with_names[num_train:]\n",
    "\n",
    "    train_graphs = [item for item in train_data]\n",
    "    test_graphs = [item for item in test_data]\n",
    "    \n",
    "    # Return the names of the graphs that were actually loaded and split\n",
    "    # For clarity, we'll return the names of the graphs that ended up in train/test\n",
    "    # and the original list of all loaded names (before split).\n",
    "    \n",
    "    return train_graphs, test_graphs, loaded_graph_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215aaead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: reverse_light_on_graphs.pt\n",
      "Loaded graph: correlated_signal_graphs.pt\n",
      "Loaded graph: reverse_light_off_graphs.pt\n",
      "Loaded graph: max_speedometer_graphs.pt\n",
      "Loaded graph: max_engine_coolant_temp_graphs.pt\n",
      "Data(x=[57, 9], edge_index=[2, 128], edge_attr=[128, 3], y=[1], node_labels=[57])\n"
     ]
    }
   ],
   "source": [
    "path = f'/home/dhkim/OpenSetGNN-main/data'\n",
    "\n",
    "train_graphs, test_graphs, graphs_names = load_and_split_graphs(path, exclude=[], train_ratio=0.8, seed=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1314d766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[69, 9], edge_index=[2, 130], edge_attr=[130, 3], y=[1], node_labels=[69], batch=[69], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "warmup_loader = DataLoader([train_graphs[0]], batch_size=1, shuffle=False)\n",
    "\n",
    "for graph in test_graphs:\n",
    "    graph.edge_attr = graph.edge_attr[:, 0].reshape(-1, 1).clone().detach()\n",
    "\n",
    "test_loader = DataLoader(test_graphs, batch_size=1, shuffle=False)\n",
    "\n",
    "dummy_input = next(iter(warmup_loader)).to('cuda')\n",
    "print(dummy_input)\n",
    "dummy_input.edge_attr = dummy_input.edge_attr[:, 0].reshape(-1, 1).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d219dbbc-0922-4a0c-85af-639bebd46f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4681"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4de7335d-a33b-4f20-9fad-94d3faea6fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(np.unique([g.y.item() for g in train_graphs]))\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64a467ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.99295936536789, 0.5312164604079275)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GAE_CLS_Link_NODE_Cosine_SupCon_2(num_features=9, embedding_size=32, projection_emb=128, activate='gelu', layer_type='gatv2', num_layers=2, directed=False, id_dim=1, num_classes = NUM_CLASSES, linear_node=True, num_id_embeddings=2048, attn_head=1)\n",
    "measure_time_gpu(dummy_input, model, 'cuda', rep=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e4d174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.1718022465705875, 0.6611099079180738)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incep = SupIncepResnet(num_classes=NUM_CLASSES)\n",
    "measure_time_gpu(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(), incep, 'cuda', rep=1000, none_gnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4d65e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0121413507461545, 0.7200512861885778)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supcon = SupCEResNet(name='resnet18', num_classes=NUM_CLASSES)\n",
    "measure_time_gpu(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(), supcon, 'cuda', rep=1000, none_gnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa9169f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up for 10 iterations...\n",
      "Starting timed inference over 100 iterations...\n",
      "Tested 100 samples.\n",
      "Mean Latency Encoding: 7.88 ms\n",
      "Median Latency Encoding: 6.81 ms\n",
      "Throughput Encoding: 126.93 samples/sec\n",
      "Mean Latency Classification: 4.40 ms\n",
      "Median Latency Classification: 3.97 ms\n",
      "Throughput Classification: 81.41 samples/sec\n",
      "Mean Latency Anomaly Detection: 2.85 ms\n",
      "Median Latency Anomaly Detection: 2.29 ms\n",
      "Throughput Anomaly Detection: 93.19 samples/sec\n"
     ]
    }
   ],
   "source": [
    "analyze_performance_time_counter(model, test_loader, device='cuda', num_warmup=10, num_repeats=100, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dfae688a-de05-431c-8ee1-cefe1d5d51a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            model_inference        43.42%     158.073ms        99.95%     363.871ms     363.871ms     163.375ms        44.89%     363.845ms     363.845ms          -4 b        -444 b           0 b      -5.78 Mb             1  \n",
      "                                aten::zeros         1.54%       5.622ms         4.72%      17.173ms     121.794us       6.418ms         1.76%      21.120ms     149.787us           4 b           0 b       1.08 Mb           0 b           141  \n",
      "            aten::_cudnn_rnn_flatten_weight         2.18%       7.926ms         5.66%      20.595ms       2.059ms       9.383ms         2.58%      20.577ms       2.058ms           0 b           0 b           0 b           0 b            10  \n",
      "                                 aten::item         0.60%       2.176ms         5.90%      21.480ms     268.500us       2.837ms         0.78%      17.709ms     221.363us           0 b           0 b           0 b           0 b            80  \n",
      "                               aten::linear         0.71%       2.583ms         4.68%      17.055ms     284.250us       2.566ms         0.70%      15.384ms     256.400us           0 b           0 b     780.00 Kb           0 b            60  \n",
      "                  aten::_local_scalar_dense         5.27%      19.194ms         5.27%      19.194ms     295.292us      14.872ms         4.09%      14.872ms     228.800us           0 b           0 b           0 b           0 b            65  \n",
      "                                aten::zero_         1.22%       4.451ms         2.50%       9.084ms      56.422us       4.413ms         1.21%      14.801ms      91.932us           0 b           0 b           0 b           0 b           161  \n",
      "                 torch_scatter::scatter_max         1.39%       5.070ms         3.79%      13.798ms     689.900us       4.228ms         1.16%      13.706ms     685.300us           0 b           0 b      30.00 Kb     -10.00 Kb            20  \n",
      "                                aten::fill_         1.91%       6.966ms         1.91%       6.966ms      29.025us      13.274ms         3.65%      13.274ms      55.308us           0 b           0 b           0 b           0 b           240  \n",
      "                         aten::index_select         2.36%       8.593ms         3.55%      12.909ms     107.575us       8.821ms         2.42%      12.058ms     100.483us           0 b           0 b       1.15 Mb           0 b           120  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 364.048ms\n",
      "Self CUDA time total: 363.982ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_performance_profiler(model, test_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30a05d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gnn_model(model, example_data, device=None, repeat=10):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device).eval()\n",
    "    example_data = example_data.to(device)\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                 record_shapes=True,\n",
    "                 profile_memory=True,\n",
    "                 with_flops=True) as prof:\n",
    "        with torch.no_grad():\n",
    "            for _ in range(repeat):\n",
    "                with record_function(\"model_inference\"):\n",
    "                    model(example_data)\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=15))\n",
    "    print(prof.key_averages().table(sort_by=\"flops\", row_limit=15))\n",
    "    # For total FLOPs (note: double to get MACs for real-valued ops)\n",
    "    total_flops = sum([item.flops for item in prof.key_averages() if hasattr(item, 'flops')])\n",
    "    print(f'Estimated total FLOPs: {clever_format([total_flops], \"%.3f\")}')\n",
    "    print(f'Estimated total MACs: {(total_flops/2)} {clever_format([total_flops/2], \"%.3f\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fba16d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference        23.44%      39.046ms        99.48%     165.712ms      16.571ms      40.154ms        24.11%     165.704ms      16.570ms         -40 b      -4.34 Kb           0 b     -14.95 Mb            10            --  \n",
      "         aten::cudnn_convolution        17.55%      29.240ms        19.74%      32.879ms     164.395us      33.163ms        19.91%      37.080ms     185.400us           0 b           0 b       5.15 Mb     -58.17 Mb           200            --  \n",
      "          aten::cudnn_batch_norm        11.89%      19.813ms        22.08%      36.781ms     183.905us      20.544ms        12.34%      36.842ms     184.210us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                     aten::empty         8.75%      14.568ms         8.75%      14.568ms      13.402us      16.206ms         9.73%      16.206ms      14.909us       4.34 Kb       4.34 Kb      64.91 Mb      64.91 Mb          1087            --  \n",
      "                 aten::clamp_min         7.38%      12.296ms        16.59%      27.643ms      81.303us      11.669ms         7.01%      26.513ms      77.979us           0 b           0 b       9.28 Mb           0 b           340            --  \n",
      "              aten::_convolution         3.98%       6.630ms        23.72%      39.509ms     197.545us       5.620ms         3.37%      42.700ms     213.500us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                aten::batch_norm         3.14%       5.232ms        28.32%      47.172ms     235.860us       5.157ms         3.10%      46.738ms     233.690us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "    aten::_batch_norm_impl_index         3.10%       5.159ms        25.18%      41.940ms     209.700us       4.739ms         2.85%      41.581ms     207.905us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                    aten::conv2d         3.43%       5.710ms        30.25%      50.388ms     251.940us       4.445ms         2.67%      51.460ms     257.300us           0 b           0 b       5.15 Mb           0 b           200    640435.520  \n",
      "               aten::convolution         3.10%       5.169ms        26.82%      44.678ms     223.390us       4.315ms         2.59%      47.015ms     235.075us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                aten::empty_like         3.00%       4.990ms         6.37%      10.617ms      53.085us       4.152ms         2.49%      10.573ms      52.865us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                   aten::resize_         2.20%       3.659ms         2.20%       3.659ms      23.306us       3.928ms         2.36%       3.928ms      25.019us           0 b           0 b       4.23 Mb       4.23 Mb           157            --  \n",
      "                      aten::relu         2.15%       3.580ms        12.73%      21.211ms     124.771us       3.407ms         2.05%      20.061ms     118.006us           0 b           0 b       4.64 Mb           0 b           170            --  \n",
      "                     aten::addmm         1.34%       2.233ms         1.52%       2.537ms     253.700us       2.258ms         1.36%       2.536ms     253.600us           0 b           0 b       5.00 Kb       5.00 Kb            10        15.360  \n",
      "                      aten::add_         1.40%       2.327ms         1.40%       2.327ms      29.087us       1.840ms         1.10%       1.840ms      23.000us           0 b           0 b           0 b           0 b            80            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 166.583ms\n",
      "Self CUDA time total: 166.524ms\n",
      "\n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    aten::conv2d         3.43%       5.710ms        30.25%      50.388ms     251.940us       4.445ms         2.67%      51.460ms     257.300us           0 b           0 b       5.15 Mb           0 b           200    640435.520  \n",
      "                     aten::addmm         1.34%       2.233ms         1.52%       2.537ms     253.700us       2.258ms         1.36%       2.536ms     253.600us           0 b           0 b       5.00 Kb       5.00 Kb            10        15.360  \n",
      "                     aten::zeros         0.28%     466.000us         0.52%     871.000us      87.100us     432.000us         0.26%     820.000us      82.000us          40 b           0 b           0 b           0 b            10            --  \n",
      "                     aten::empty         8.75%      14.568ms         8.75%      14.568ms      13.402us      16.206ms         9.73%      16.206ms      14.909us       4.34 Kb       4.34 Kb      64.91 Mb      64.91 Mb          1087            --  \n",
      "                     aten::zero_         0.05%      79.000us         0.05%      79.000us       7.900us      65.000us         0.04%      65.000us       6.500us           0 b           0 b           0 b           0 b            10            --  \n",
      "                 model_inference        23.44%      39.046ms        99.48%     165.712ms      16.571ms      40.154ms        24.11%     165.704ms      16.570ms         -40 b      -4.34 Kb           0 b     -14.95 Mb            10            --  \n",
      "               aten::convolution         3.10%       5.169ms        26.82%      44.678ms     223.390us       4.315ms         2.59%      47.015ms     235.075us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "              aten::_convolution         3.98%       6.630ms        23.72%      39.509ms     197.545us       5.620ms         3.37%      42.700ms     213.500us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "         aten::cudnn_convolution        17.55%      29.240ms        19.74%      32.879ms     164.395us      33.163ms        19.91%      37.080ms     185.400us           0 b           0 b       5.15 Mb     -58.17 Mb           200            --  \n",
      "                aten::batch_norm         3.14%       5.232ms        28.32%      47.172ms     235.860us       5.157ms         3.10%      46.738ms     233.690us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "    aten::_batch_norm_impl_index         3.10%       5.159ms        25.18%      41.940ms     209.700us       4.739ms         2.85%      41.581ms     207.905us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "          aten::cudnn_batch_norm        11.89%      19.813ms        22.08%      36.781ms     183.905us      20.544ms        12.34%      36.842ms     184.210us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                aten::empty_like         3.00%       4.990ms         6.37%      10.617ms      53.085us       4.152ms         2.49%      10.573ms      52.865us           0 b           0 b       5.15 Mb           0 b           200            --  \n",
      "                      aten::view         0.96%       1.602ms         0.96%       1.602ms       8.707us       1.424ms         0.86%       1.424ms       7.739us           0 b           0 b           0 b           0 b           184            --  \n",
      "                      aten::relu         2.15%       3.580ms        12.73%      21.211ms     124.771us       3.407ms         2.05%      20.061ms     118.006us           0 b           0 b       4.64 Mb           0 b           170            --  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 166.583ms\n",
      "Self CUDA time total: 166.524ms\n",
      "\n",
      "Estimated total FLOPs: 640.451M\n",
      "Estimated total MACs: 320225440.0 320.225M\n"
     ]
    }
   ],
   "source": [
    "profile_gnn_model(supcon.to(device='cpu'), torch.randn(1, 1, 29, 29, dtype=torch.float).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecb460ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            model_inference        38.59%     125.039ms        99.77%     323.262ms      32.326ms     131.166ms        40.49%     323.252ms      32.325ms     271.14 Kb    -126.84 Kb    -274.00 Kb      -5.57 Mb            10            --  \n",
      "                                aten::copy_         7.64%      24.758ms         7.64%      24.758ms      57.310us      24.883ms         7.68%      24.883ms      57.600us           0 b           0 b           0 b           0 b           432            --  \n",
      "                             aten::_to_copy         5.77%      18.703ms        16.18%      52.415ms     124.206us      17.271ms         5.33%      51.124ms     121.147us     393.68 Kb           0 b     190.00 Kb           0 b           422            --  \n",
      "                                   aten::to         3.72%      12.044ms        19.90%      64.459ms     100.717us      11.571ms         3.57%      62.695ms      97.961us     393.68 Kb           0 b     190.00 Kb           0 b           640            --  \n",
      "                        aten::empty_strided         3.15%      10.194ms         3.15%      10.194ms      22.553us      10.223ms         3.16%      10.223ms      22.617us     393.68 Kb     393.68 Kb     300.00 Kb     300.00 Kb           452            --  \n",
      "                         aten::scatter_add_         2.41%       7.804ms         3.03%       9.829ms      81.908us       7.856ms         2.43%       9.664ms      80.533us           0 b           0 b           0 b           0 b           120            --  \n",
      "                         aten::index_select         2.17%       7.035ms         3.47%      11.249ms      93.742us       7.752ms         2.39%      11.238ms      93.650us           0 b           0 b       1.04 Mb           0 b           120            --  \n",
      "    aten::_has_compatible_shallow_copy_type         2.95%       9.555ms         2.95%       9.555ms       8.097us       7.272ms         2.24%       7.272ms       6.163us           0 b           0 b           0 b           0 b          1180            --  \n",
      "                                aten::empty         2.08%       6.753ms         2.08%       6.753ms      17.360us       6.566ms         2.03%       6.566ms      16.879us       4.34 Kb       4.34 Kb     299.50 Kb     299.50 Kb           389            --  \n",
      "                           aten::as_strided         2.38%       7.696ms         2.38%       7.696ms       8.991us       6.474ms         2.00%       6.474ms       7.563us           0 b           0 b           0 b           0 b           856            --  \n",
      "                               aten::expand         1.85%       5.987ms         2.47%       8.016ms      36.436us       5.919ms         1.83%       7.598ms      34.536us           0 b           0 b           0 b           0 b           220            --  \n",
      "                            aten::unsqueeze         1.70%       5.507ms         2.23%       7.210ms      36.050us       5.331ms         1.65%       6.795ms      33.975us           0 b           0 b           0 b           0 b           200            --  \n",
      "                                aten::zeros         1.49%       4.830ms         3.84%      12.430ms      95.615us       4.851ms         1.50%      12.392ms      95.323us          40 b           0 b     230.00 Kb           0 b           130            --  \n",
      "                                aten::addmm         1.45%       4.695ms         1.87%       6.067ms     151.675us       4.839ms         1.49%       6.133ms     153.325us           0 b           0 b     360.00 Kb     360.00 Kb            40      3621.120  \n",
      "                                   aten::eq         1.36%       4.418ms         1.36%       4.418ms     220.900us       4.643ms         1.43%       4.643ms     232.150us           0 b           0 b      10.00 Kb      10.00 Kb            20            --  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 323.991ms\n",
      "Self CUDA time total: 323.957ms\n",
      "\n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total KFLOPs  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                aten::addmm         1.45%       4.695ms         1.87%       6.067ms     151.675us       4.839ms         1.49%       6.133ms     153.325us           0 b           0 b     360.00 Kb     360.00 Kb            40      3621.120  \n",
      "                                  aten::mul         1.38%       4.469ms         1.38%       4.469ms      44.690us       4.423ms         1.37%       4.423ms      44.230us           0 b           0 b       1.17 Mb       1.17 Mb           100       255.360  \n",
      "                                   aten::mm         0.39%       1.257ms         0.39%       1.257ms      62.850us       1.223ms         0.38%       1.223ms      61.150us           0 b           0 b     330.00 Kb     330.00 Kb            20       166.400  \n",
      "                                  aten::add         1.08%       3.493ms         1.08%       3.493ms      43.663us       3.308ms         1.02%       3.308ms      41.350us           0 b           0 b     540.00 Kb     540.00 Kb            80       130.600  \n",
      "                                aten::zeros         1.49%       4.830ms         3.84%      12.430ms      95.615us       4.851ms         1.50%      12.392ms      95.323us          40 b           0 b     230.00 Kb           0 b           130            --  \n",
      "                                aten::empty         2.08%       6.753ms         2.08%       6.753ms      17.360us       6.566ms         2.03%       6.566ms      16.879us       4.34 Kb       4.34 Kb     299.50 Kb     299.50 Kb           389            --  \n",
      "                                aten::zero_         0.98%       3.164ms         1.77%       5.730ms      38.200us       3.144ms         0.97%       6.080ms      40.533us           0 b           0 b           0 b           0 b           150            --  \n",
      "                            model_inference        38.59%     125.039ms        99.77%     323.262ms      32.326ms     131.166ms        40.49%     323.252ms      32.325ms     271.14 Kb    -126.84 Kb    -274.00 Kb      -5.57 Mb            10            --  \n",
      "                                   aten::to         3.72%      12.044ms        19.90%      64.459ms     100.717us      11.571ms         3.57%      62.695ms      97.961us     393.68 Kb           0 b     190.00 Kb           0 b           640            --  \n",
      "                             aten::_to_copy         5.77%      18.703ms        16.18%      52.415ms     124.206us      17.271ms         5.33%      51.124ms     121.147us     393.68 Kb           0 b     190.00 Kb           0 b           422            --  \n",
      "                        aten::empty_strided         3.15%      10.194ms         3.15%      10.194ms      22.553us      10.223ms         3.16%      10.223ms      22.617us     393.68 Kb     393.68 Kb     300.00 Kb     300.00 Kb           452            --  \n",
      "                                aten::copy_         7.64%      24.758ms         7.64%      24.758ms      57.310us      24.883ms         7.68%      24.883ms      57.600us           0 b           0 b           0 b           0 b           432            --  \n",
      "    aten::_has_compatible_shallow_copy_type         2.95%       9.555ms         2.95%       9.555ms       8.097us       7.272ms         2.24%       7.272ms       6.163us           0 b           0 b           0 b           0 b          1180            --  \n",
      "                               aten::linear         0.86%       2.783ms         4.45%      14.421ms     240.350us       2.625ms         0.81%      14.090ms     234.833us           0 b           0 b     690.00 Kb           0 b            60            --  \n",
      "                                    aten::t         0.47%       1.527ms         1.11%       3.604ms      60.067us       1.456ms         0.45%       3.442ms      57.367us           0 b           0 b           0 b           0 b            60            --  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 323.991ms\n",
      "Self CUDA time total: 323.957ms\n",
      "\n",
      "Estimated total FLOPs: 4.173M\n",
      "Estimated total MACs: 2086740.0 2.087M\n"
     ]
    }
   ],
   "source": [
    "dummy_input = dummy_input.to(device='cpu')\n",
    "model = model.to(device='cpu')\n",
    "profile_gnn_model(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47bd1543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 97.191M\n",
      "Params: 1.695M\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(incep, inputs=(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(),), verbose=False)\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bcf8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 32.561M\n",
      "Params: 700.662K\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(supcon, inputs=(torch.randn(1, 1, 29, 29, dtype=torch.float).cuda(),), verbose=False)\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48100a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 0.0\n",
      "Params: 0.0\n"
     ]
    }
   ],
   "source": [
    "macs, params = thopprofile(model, inputs=(dummy_input,), verbose=False)\n",
    "\n",
    "print(f\"MACs: {macs}\") # thop reports MACs\n",
    "print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393dc5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyg_env)",
   "language": "python",
   "name": "pyg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
